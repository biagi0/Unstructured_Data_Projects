companyid,headline,mostimportantdateutc,keydeveventtypeid,keydeveventtypename,companyname,audiolengthsec,transcriptid,transcriptcomponentid,transcriptcomponenttypename,transcriptpersonname,companyofperson,speakertypename,componentorder,componenttext,word_count
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175509.0,Presentation Operator Message,Operator,,Operator,0,"Good afternoon. My name is Christina, and I'm your conference operator today. Welcome to NVIDIA's financial results conference call. [Operator Instructions] Thank you. I'll now turn the call over to Simona Jankowski, Vice President of Investor Relations, to begin your conference.",41
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175510.0,Presenter Speech,Simona Stefan Jankowski,,Executives,1,"Thank you. Good afternoon, everyone, and welcome to NVIDIA's Conference Call for the Fourth Quarter of Fiscal 2020. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the first quarter of fiscal 2021. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. 
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, February 13, 2020, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. 
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. 
With that, let me turn the call over to Colette.",254
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175511.0,Presenter Speech,Colette Kress,,Executives,2,"Thanks, Simona. Q4 revenue was $3.11 billion, up 41% year-on-year and up 3% sequentially, well above our outlook, reflecting upside in our data center and gaming businesses. Full year revenue was $10.9 billion, down 7%. We recovered from the excess channel inventory in gaming and an earlier pause in hyperscale spending and exited the year with great momentum. 
Starting with gaming. Revenue of $1.49 billion was up 56% year-on-year and down 10% sequentially. Full year gaming revenue was $5.52 billion, down 12% from our prior year. 
We enjoyed strong end demand for our desktop and notebook GPUs. Let me give you some more details. Our gaming lineup was exceptionally well positioned for the holidays with the unique ray tracing capabilities of our RTX GPUs and incredible performance at every price point. From the Singles Day shopping event in China through the Christmas season in the West, channel demand was strong for our entire stack. Fueling this were new blockbuster games like Call of Duty: Modern Warfare, continued eSports momentum and new RTX Super products. With RTX price points as low as $299, ray tracing is now the sweet spot for PC gamers. 
Gaming is thriving and gamers prefer GeForce. The global phenomenon of eSports keeps gaming momentum with an audience now exceeding 440 million, up over 30% in just 2 years according to Newzoo. The League of Legends World Championship brought more than 100 million viewers, on par with this month's Super Bowl. 
Ray tracing titles continue to come to market, and GeForce RTX GPUs are the only ones that support this important technology. This quarter, Wolfenstein: Young blood and Deliver Us The Moon were the latest titles to support ray tracing as well as NVIDIA's Deep Learning Super Sampling technique, which also uses AI to boost performance. With the proliferation of RTX-enabled games and our best ever top-to-bottom performance, we are solidly into the Turing architecture upgrade cycle. Gamers continue to move to higher-end GPUs, seeking better performance and support for ray tracing.  
Gaming laptops posted double-digit year-on-year growth for the eighth consecutive quarter. The category continues to expand, driven by appealing thin and light form factors with fantastic graphics performance. This holiday season, retailers stocked a record 125 gaming laptops based on NVIDIA GPUs, up from 94 last year, with our Max-Q designs up 2x. At CES, we launched the world's first 14-inch GeForce RTX laptop with ASUS. We also continue to expand our Studio lineup of laptops for the fast-growing population of freelance creators, designers and YouTubers with 13 new RTX Studio systems introduced at CES. Powered by Turing GPUs, these systems are optimized for over 55 creative and design applications with RTX accelerated ray tracing and/or AI. 
Last week, we launched our GeForce NOW cloud gaming service. Powered by GeForce, GeForce NOW is the first cloud gaming service to deliver ray trace games. It's also the only open platform so gamers can enjoy the games they already have and use their existing store accounts without having to repurchase games. GeForce NOW enables PC games on Macs, Windows, PCs, TVs, Mobile devices and soon, Chromebooks. GFN has a freemium business model that includes 2 membership plans: a free membership with standard access; and the Founders tier with a starting price of $4.99 per month, which gives priority access and RTX ray tracing support. 
Our goal with GeForce NOW is to expand GeForce gaming to more gamers. About 80% of GeForce NOW gamers are playing on underpowered PCs or devices with Mac OS or Android. With GeForce NOW, they are able to enjoy PC gaming on a GeForce GPU in the cloud. GeForce now can expand GeForce well beyond the roughly 200 million gamers we reach today. 
Separately, we entered into a collaboration with Tencent, the world's largest gaming platform, to bring PC gaming in the cloud to China, the world's largest gaming market. NVIDIA GPU technology will power Tencent's Start cloud gaming service, which is in early testing stages. 
Moving to data center. Revenue was a record $968 million, up 43% year-on-year and up 33% sequentially, our strongest ever sequential growth in dollar terms. Full year fiscal year '20 data center revenue was a record $2.98 billion, up 2% from the prior year. Strong growth was fueled by hyperscale and vertical industry and customers. Hyperscale demand was driven by purchases of both our training and inference products in support of key AI workloads, such as natural language understanding, conversational AI and deep recommendators. Hyperscale demand was also driven by cloud computing. AWS now makes the T4 available in every region. This underscores the versatility of the T4, which excels at a wide array of high-performance computing workloads, including AI inference, cloud gaming, rendering and virtual desktop. 
Vertical industry growth was driven primarily by consumer Internet companies. Other verticals such as retail, health care and logistics continue to grow from early-stage build-outs with a strong foundation of deep learning engagements, and we see an expanding set of opportunities across high-performance computing, data science and edge computing applications. 
T4, our inference platform, had another strong quarter, with shipments up 4x year-on-year, driven by public cloud deployments as well as edge AI video analytics applications. T4 and V100, reflecting strong demand for inference and training, respectfully, set records this quarter for both shipments and revenue. 
IVA's NVIDIA remains the leading platform for AI model training. NVIDIA's inference platform is gaining wide use by some of the world's leading enterprise and consumer Internet companies, including American Express, Microsoft, PayPal, Pinterest, Snap and Twitter. 
The industry continues to do groundbreaking AI work for NVIDIA. For example, Microsoft's biggest quality improvements made over the past year in its Bing search engine stemmed from its use of NVIDIA GPUs and software for training and inference of its natural language understanding models. These DNN transformer models popularized by BERT have computational requirements for training that are in the order of magnitude higher than earlier image-based models. Conversational AI is a major new workload, requiring GPUs for inference to achieve high throughput within the desired low latency. Indeed, Microsoft cited an inference throughput increase of up to 800x on NVIDIA GPUs compared with CPUs, enabling it to serve over 1 million BERT inferences per second worldwide. And just this week, Microsoft researchers announced a new breakthrough in natural language processing with the largest ever publicized model trained on NVIDIA DGX-2. This advances the state of the art for AI assistance and tasks, such as answering questions, summarization and natural language generation. 
Recommendators are also an important machine learning model for the Internet, powering billions of queries per second. The industry is moving to deep recommendators such as wide and deep model, which leverage deep learning to enable automatic feature learning and to support unstructured content. Running these models on GPUs can dramatically increase inference throughput and reduce latency compared with CPUs. For example, Alibaba's and Baidu's recommendation engines run on NVIDIA AI, boosting their inference throughput by orders of magnitudes beyond CPUs. Deep recommendators enabled Alibaba to achieve 10% increase in click-through rates. 
We also announced the availability of a new GPU-accelerated supercomputer on Microsoft Azure. It enables customers for the first time to rent an entire AI supercomputer on demand from their desk, matching the capabilities of large on-premise supercomputers that can take months to deploy. And in Europe, energy company Eni announced the world's fastest industrial supercomputer based on NVIDIA GPUs. 
AI has even come to pizza delivery. At the National Retail Federations Annual Conference last month, we announced Domino's as a customer deploying our platform for deep learning and data science applications, helping with customer engagement and order accuracy prediction. More broadly in retail, we have seen a significant increase in the adoption of NVIDIA's edge computing offerings by large retailers for powering AI applications that reduce shrinkage, optimize logistics and create operational efficiencies. 
At the SC19 Supercomputing conference, we introduced a reference design platform for GPU-accelerated ARM-based servers, along with ecosystem partners, ARM, Ampere Computing, Fujitsu and Marvell. We made available our ARM-compatible software development kit consisting of NVIDIA CUDA-X libraries and development tools for accelerating computing. This opens the floodgate of innovation to support growing new applications from hyperscale cloud to Exascale supercomputing. We also introduced NVIDIA Magnum IO, a suite of software optimized to eliminate storage and input/output bottlenecks. Magnum IO delivers up to 20x faster data processing for multi-server, multi-GPU computing nodes when working with massive data sets to carry out complex financial analysis, climate modeling and other workloads for data scientists, high-performance computing and AI researchers.
Finally, we introduced TensorRT 7, the seventh generation of our inference software development kit, which speeds up components of conversational AI by 10x comparing to running on CPUs. This helps drive latency below the 300 millisecond threshold considered necessary for real-time interactions supporting our growth in conversational AI. 
Moving to ProVis. Revenue reached a record $331 million, up 13% year-on-year and up 2% sequentially. Full year revenue was a record $1.21 billion, an increase of 7% from the prior year. ProVis accelerated in Q4 as the rollout of more RTX-enabled applications is driving strong upgrade cycle for our Turing GPUs. RTX is also opening up new market segment opportunities, such as rendering and studio for freelance creatives.
In November, V-ray, Arnold and Blender software renderers began shipping with RTX technology. These joined our leading creative and design applications, including Premier Pro, Dimension, SOLIDWORKS, CATIA and Maya. With RTX, these applications enable enhanced creativity and notable productivity gains. In Blender Cycles, for example, real-time rendering performance is boosted 4x versus a CPU. RTX is now supported by more than 40 leading creative and design applications, reaching a combined user base of over 40 million. 
Finally, turning to automotive. Revenue was $163 million, flat from a year ago and up 1% sequentially. Full year revenue reached a record $700 million, up 9% year-on-year. During the quarter, we announced DRIVE AGX Orin, the next-generation platform for autonomous vehicles and robots, powered by our new Orin SoC and delivering nearly 7x the performance of the previous generation Xavier SoC. The platform scales from level 2 plus AI-assisted driving up to level 5 fully driverless operation. Orin is software-defined and compatible with Xavier, allowing developers to leverage their investment across multiple product generations. 
Moving to the rest of the P&L. Q4 GAAP gross margins was 64.9% and non-GAAP was 65.4%, up sequentially, largely reflecting a higher contribution of data center products. Q4 GAAP operating expenses were $1.02 billion and non-GAAP operating expenses were $810 million, up 12% and 7% year-on-year, respectively. 
Q4 GAAP EPS was $1.53, up 66% from a year earlier. Non-GAAP EPS was $1.89, up 136% from a year ago. Q4 cash from operations was $1.46 billion. Fiscal year '20 cash flow from operations was a record $4.76 billion. 
With that, let me turn the outlook for the first quarter of fiscal 2021. The outlook does not include any contribution from the pending acquisition of Mellanox. We are engaged and progressing with China on the regulatory approval and believe the acquisition will likely close in the first part of calendar 2020. 
Before we get to the new -- the numbers, let me comment on the impact of the coronavirus. While it is still early and the ultimate effect is difficult to estimate, we have reduced our Q1 revenue outlook by $100 million to account for the potential impact. We expect revenue to be $3 billion, plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 65% and 65.4%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $1.05 billion and $835 million, respectively. GAAP and non-GAAP OI&E are both expected to be income of approximately $25 million. GAAP and non-GAAP tax rates are both expected to be 9%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $150 million to $170 million. Further financial details are included in the CFO commentary and other information available on the IR website. 
In closing, let me highlight an upcoming event for the financial community. We will be at the Morgan Stanley Technology, Media and Telecom Conference on March 2 in San Francisco. 
With that, we will now open the call for questions. Operator, will you please poll for questions.",2057
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175512.0,Question and Answer Operator Message,Operator,,Operator,3,"[Operator Instructions] 
And our first question comes from the line of Toshiya Hari with Goldman Sachs.",16
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175513.0,Question,Toshiya Hari,,Analysts,4,"I guess on data center, Colette or Jensen, can you speak to some of the areas that drove the upside in the quarter? You talked about inference and -- both the T4 and the V100 having record quarters but relative to your internal expectations. What were some of the businesses that drove the upside? And if you can also speak to the breadth of your customer profile today relative to a couple of years ago, how that's expanded. That would be helpful as well.",84
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175514.0,Answer,Jen-Hsun Huang,,Executives,5,"Yes. Toshiya, thanks a lot for question. The primary driver for growth is AI. There are 4 fundamental dynamics. The first is that the AI models that are being created are achieving breakthroughs and quite amazing breakthroughs, in fact, in natural language understanding, in conversational AI and recommendation systems. And you know this, but for the others in the audience, recommendation systems are essentially the engine of the Internet today. And the reason for that is because there are so many items in the world, whether it's a store or whether it's content or websites or information you are querying, there are hundreds of billions, trillions, and depending on how you count it, hundreds of trillions of items in the world. And there are billions of people, each with their own characteristics and their countless contexts. And between the items, the people, the users and the various contexts that we're in, location and what you're looking for and weather or what's happening in the environment, those kind of contexts affects the search query that -- the answer they provide you. The recommendation system is just foundational now to search. And some people have said this is the end of search in the beginning and the era of recommendation systems. Work is being done everywhere around the world in advancing recommendation systems. And very first time over the last year, it's been able to be done in deep learning. 
And so the first thing is just the breakthroughs in AI. The second is production AI, which means that whereas we had significant and we continue to have significant opportunities in training because the model is getting larger, and there are more of them, we're seeing a lot of these models going into production, and that business is called inference. Inference, as Colette mentioned, grew 4x year-over-year. It's a substantial part of our business now. But one of the interesting statistics is TensorRT 7, the entire TensorRT download this year was about 500,000, a doubling over a year ago. What most people don't understand about inference is it's an incredibly complex computational problem, but it's an enormously complex software problem. And so the second dynamic is moving from training or growing from training and models going into production called inference. 
The third is the growth, not just in hyperscale anymore, but in public cloud and in vertical industries. Public cloud because of thousands of AI start-ups that are now developing AI software in the cloud. And the OpEx model works much better for them as they're younger. When they become larger, they could decide to build their own data center infrastructure on-prem, but the thousands of start-ups start their lives in the cloud. 
We're also seeing really great success in verticals. One of the most exciting vertical is logistics. Logistics, retail, warehousing. We announced, I think, this quarter or last -- end of last quarter, USPS, American Express, Walmart, just large companies who have enormous amounts of data that they're trying to do data analytics on and do predictive analytics on. And so the third dynamic is the growth in -- beyond hyperscale and public cloud as well as vertical industries. 
And then the last dynamic is being talked about a lot, and this is really, really exciting, and it's called edge AI. We used to call it industries and AI where the action is. But the industry is now called edge AI. We're seeing a lot of excitement there. And the reason for that is you need to have low latency inference. You might not be able to stream data all the way to the cloud for cost reasons or data sovereignty reasons, and you need the response time. And so those 4 dynamics around AI really drove our growth.",629
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175515.0,Question and Answer Operator Message,Operator,,Operator,6,Your next question comes from the line of Joe Moore with Morgan Stanley.,13
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175516.0,Question,Joseph Moore,,Analysts,7,"Great. Just following up on that. As you look back at the last 12 months and the deceleration that you saw in your HPC cloud business, now that you have the perspective of seeing what's driving the rebound, any thoughts on what drove it to slow down in the first place? Was it just digestion? Was it sort of a handoff from image recognition to these newer applications that you just talked about? Just help us what happened there? And I guess as it pertains to the future, do we think of this as a business that will have that kind of lumpiness to it?",105
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175517.0,Answer,Jen-Hsun Huang,,Executives,8,"Yes. That's a really good question. In fact, if you look backwards, now we only have the benefit of history. The deep recommendation systems, the natural language understanding breakthroughs, the conversational AI breakthroughs, all happened in this last year. And the velocity by which the industry captured the benefits here and continue to evolve and advance from these what so-called transformer models was really quite incredible. And so all of a sudden, the number of breakthroughs in AI has just grown tremendously, and these models have grown tremendously. Just this last week, Microsoft announced that they've trained a neural net model in collaboration with work that we did, we call Megatron, increased the size of the model from 7.5 billion parameters to 17.5 billion parameters. And the accuracy of their natural language understanding has just -- has really been boosted. 
And so the models are -- AI is finding really fantastic breakthroughs, and models are getting bigger and there are more of them. And when you look back and look at when these breakthroughs happened, it essentially happened this last year. 
The second, we've been working on inference for some time. And until this last year, very few of those inference models went into production. And now we have deep learning models across all of the hyperscalers in production. And this last year, we saw really great growth in inference. 
The third dynamic is public clouds. All these AI startups, they are being started all over the world, there's about 6,000 of them, they're starting to develop and be able to put their models into production. And with the scale out of AWS, we now have T4s in every single geography. So the combination of the availability of our GPUs in the cloud, and the startups and vertical industries deploying their AI models into production, the combination of all that just kind of came together. And all of that happened this last year. And as a result, we had record sales of V100s and T4s. And so we're quite excited with the developments, and it's all really powered by AI.",350
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175518.0,Question and Answer Operator Message,Operator,,Operator,9,Your next question comes from the line of Vivek Arya with Bank of America Securities.,15
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175519.0,Question,Vivek Arya,,Analysts,10,"Congratulations on returning the business back to the strong growth. Jensen, I wanted to ask about how you are positioned from a supply perspective for this coming year? Your main foundry is running pretty tight. How will you be able to support the 20% or so growth here that many investors are looking for? If you could just give us some commentary on how you're positioned from a supply perspective, that will be very helpful.",75
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175520.0,Answer,Jen-Hsun Huang,,Executives,11,"Well, I think we're in pretty good shape on supply. We surely won't have ample supply. It is true that the industry is tight and the combination of supporting multiple processes, multiple fabs across our partner, TSMC. We've got a lot of different factories and a lot of different -- several different nodes of process qualified. I think we're in good shape. And so we just have to watch it closely. And we're working very closely with all of our customers and forecasting. And of course, that gives us better visibility as well and -- but all of us have to do a better job forecasting, and we're working very closely between our customers and our foundry partners, TSMC.",119
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175521.0,Question and Answer Operator Message,Operator,,Operator,12,Your next question comes from the line of Timothy Arcuri with UBS.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175522.0,Question,Timothy Arcuri,,Analysts,13,"Colette, I'm wondering if you can give us -- in data center, if you can give us a little idea of what the mix was between industries and hyperscale. I think last quarter, hyperscale was a little bit less than 50%. Can you give us maybe the mix or how much it was up, something like that?",57
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175523.0,Answer,Colette Kress,,Executives,14,"Yes. Tim, thanks for the question. Similar to what we had seen last quarter, with all things growing as we moved into this quarter, growth in terms of the hyperscales, continued expansion in terms of those vertical industries and even in the cloud instances. We're still looking at around the same split of 50-50 between our hyperscales and our vertical industries and maybe a little bit tad below 50 in terms of our total overall hyperscales.",76
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175524.0,Question and Answer Operator Message,Operator,,Operator,15,Your next question comes from the line of Aaron Rakers with Wells Fargo.,13
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175525.0,Question,Aaron Rakers,,Analysts,16,"Congratulations on the results. When I look at the numbers, the growth on an absolute basis sequentially in data center was almost 2x or north of 2x, what we've seen in the past as far as the absolute sequential change. Through the course of this quarter, you were pretty clear that you would expect to see an acceleration of growth in the December quarter. I'm just curious of how you think about that going into the April quarter? And how we should think about that growth rate through the course of this year? If you can give us any kind of framework. 
And Jensen, just curious, I mean, as you think about the bigger picture, where do you think we stand from an industry perspective today in terms of the amount or the attach rate of GPUs is for acceleration in the server market? And where do you think that might be looking out over the next 3 years or so?",161
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175526.0,Answer,Jen-Hsun Huang,,Executives,17,"Thanks, Aaron. Colette, do you want to go first?",9
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175527.0,Answer,Colette Kress,,Executives,18,"Sure. When we think about going into Q1 and our data center overall growth, we do expect to see continued growth, both going into Q1. We believe our visibility still remain positive quite well, and  we're expecting that as we move into it and go forward.",46
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175528.0,Answer,Jen-Hsun Huang,,Executives,19,"Yes. Aaron, I believe that every query on the Internet will be accelerated someday. And at the very core of it, most -- almost all queries will have some natural language understanding component to it. Almost all queries will have to sort through and make a recommendation from the trillions of possibilities, filter it down and recommend a handful of recommended answers to your queries. Whether it's shopping or movies or just asking locations or even asking a question, the number of the possibilities of all the answers versus what is best answer is -- needs to be filtered down. And that filtering process is called recommendation. That recommendation system is really complex, and deep learning is going to be involved in all that. That's the first thing. I believe that every query will be accelerated. 
The second is, as you know, CPU scaling has really slowed, and there's just no 2 ways about it. It's not a marketing thing. It's a physics thing. And the ability for CPUs to continue to scale without increasing cost or increasing power has ended. And it's called the end of Dennard scaling. And so there has to be another approach. The combination of the emergence of deep learning and the use of artificial intelligence and the amount of computation that's necessary to -- for every single query but the benefit that comes along with that, and the end of Dennard scaling, suggests that there needs to be another approach, and we believe that approach is acceleration. 
Now our approach for acceleration is fundamentally different than an accelerator. Notice, we never say accelerator, we say accelerated computing. And the reason for that is because we believe that a software-defined data center will have all kinds of different AIs. The AIs will continue to evolve, the models will continue to evolve and get larger, and a software-defined data center needs to be programmable. It is one of the reasons why we've been so successful. And if you go back and think about all the questions that have been asked of me over the last 3 or 4 years around this area, the consistency of the answer has to do with the programmability of architecture, the richness of the software, the difficulties of the compilers, the ever-growing size of the models, the diversity of the models and the advances that these models are creating. And so we're seeing the beginning of a new computing era. 
And a fixed function accelerator is simply not the right answer. And so we believe that the future is going to be accelerated. It's going to require an accelerated computing platform, and software richness is really vital, so that these data centers could be software defined. And so I think that we're in the early innings, the early innings, very, very early innings of this new future. And I think that accelerated computing is going to become more and more important.",490
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175529.0,Question and Answer Operator Message,Operator,,Operator,20,Your next question comes from the line of Matt Ramsay with Cowen.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175530.0,Question,Matthew Ramsay,,Analysts,21,"Obviously, congratulations on the data center success. I wanted to ask a little bit, Colette, about the -- you took $100 million out for coronavirus, and I wanted to ask a little bit about how you got to that number. Really 2 pieces. One, if you could remind us maybe in terms of units or revenue, how -- what percentage of your gaming business is within China? And as you look at that $100 million that you put out of the guidance, are you thinking about that from a demand disruption perspective? Or are you thinking about it from something in the supply chain that might limit your sales?",109
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175531.0,Answer,Colette Kress,,Executives,22,"Sure. Thanks for the question, Matt. So it's really still quite early in terms of trying to figure out what the impact from the overall coronavirus may be. So we're not necessarily precise in terms of our estimate. Yes, our estimates are split between an impact possibly on gaming and data center and split pretty much equally. The $100 million also reflects what may be supply challenges or maybe overall demand. But we're still looking at those to get a better understanding where we think that might be. 
In terms of our business and our business makeup, yes, our overall China business for gaming is an important piece. We have about 30% of our overall China gaming as a percentage of our overall gaming business. For data center, it's -- it moves quite a bit. They are a very important market for us, but it moves from quarter-to-quarter just based on the overall end customer mix as well as the system builds that they may choose. So it's a little harder to determine.",173
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175532.0,Question and Answer Operator Message,Operator,,Operator,23,Your next question comes from the line of Harlan Sur with JPMorgan.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175533.0,Question,Harlan Sur,,Analysts,24,"Congratulations on the strong results and guidance. On gaming -- yes, no problem. Good to see the recent launch of your GeForce NOW service. But on the partnership with Tencent on cloud gaming, seems like Tencent should have a smoother transition to the cloud model. They are the largest gaming company in the world, so they own many of the games. They also have their own data center infrastructure already in place. But how is the NVIDIA team going to be supporting this partnership? Is it going to be deal your GeForce NOW hardware framework? Or will you just be supporting them with your standalone GPU products? And when do you expect the service to go mainstream?",117
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175534.0,Answer,Jen-Hsun Huang,,Executives,25,"Let's see. Tencent is the world's largest publisher. China represents about 1/3 of the world's gaming, and transitioning to the cloud is going to be a long-term journey. And the reason for that is because Internet connection is not consistent throughout the entire market. And a lot of application still needs to be onboarded, and we're working very closely with them. We're super enthusiastic about it. If we're successful long term, and we're talking about an extra 1 billion gamers that we might be able to reach. And so I think that this is an exciting opportunity, just the long-term journey. 
Now here in the West, we've had a lot more opportunity to refine the connections around the world and working through the data centers, the local hubs as well as people's WiFi routers at home. And so we've been in beta for quite some time, as you know. And here in the West, our platform is open. And we have several hundred games now and we're in the process of onboarding another 1,500 games. We're the only cloud platform that's based on Windows and allows us to be able to bring PC games to the cloud. And so the reach is -- we've had more experience here in the West with reach, and we've had -- we obviously have a lot more games that we can onboard. But I'm super enthusiastic about the partnership we have with Tencent. Overall, our GeForce NOW -- you guys saw the launch, it's -- the reception has been fantastic, the reviews have been fantastic. Our strategy has 3 components. There's the GeForce NOW service that we provide ourselves. We also have GeForce NOW alliances with telcos around the world to reach the regions around the world that we don't have a presence in. And that is going super well, and I'm excited about that. And then lastly, partnerships with large publishers, for example, like Tencent. And we offer them our platform, of course, and a great deal of software and just a lot of engineering that has to be done in collaboration to refine the service.",354
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175535.0,Question and Answer Operator Message,Operator,,Operator,26,Your next question comes from the line of C.J. Muse with Evercore.,13
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175536.0,Question,Christopher Muse,,Analysts,27,"I guess a question on the gaming side. If I look at your overall revenue guide, it would seem to suggest that you're looking for typically, I guess, better seasonal trends into April. And I guess can you speak to that? And then how are you seeing desktop gaming demand with ray tracing content becoming more available? How should we think about the growth trajectory through 2020? And then just really as a modeling question as part of gaming. With notebook now 1/3 of the revenues, how should we think about kind of the seasonality going into April and July for that part of your business?",106
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175537.0,Answer,Jen-Hsun Huang,,Executives,28,"Yes. So C.J., I want to go first, and then Colette is going take it home here. So the first part of it is this, our gaming business has at the end -- I'm sorry. Okay. Our gaming business, the end market demand is really terrific. It's really healthy. It's been healthy throughout the whole year. And it's pretty clear that RTX is doing fantastic. And it's very -- it's super clear now that ray tracing is the most important new feature of next-generation graphics. We have 30 -- over 30 games that have been announced, 11 games or so that have been shipped. The pipeline of ray tracing games that are going to be coming out is just really, really exciting. The second factor -- and one more thing about RTX, we finally have taken RTX down to $299. So it's now at the sweet spot of gaming. And so RTX is doing fantastic. The sell-through is fantastic all over the world. 
The second part of our business that is changing in gaming is this -- the amount of notebook sales and the success of Nintendo Switch has really changed the profile of our overall gaming business. Our notebook business, as Colette mentioned earlier, has seen double-digit growth for 8 consecutive quarters, and this is unquestionably a new gaming category. Like it's a new game console. This is going to be the largest game console in the world, I believe. And the reason for that is because there are more people with laptops than there are of any other device. And so the fact that we've been able to get RTX into a thin and light notebook, a thin and light notebook, is really a breakthrough. And it's one of the reasons why we're seeing such great success in notebook. Between the notebook business and our Nintendo Switch business, the profile of gaming overall has changed and has become more seasonal. It's more seasonal because devices, systems, like notebooks and Switch, are built largely in 2 quarters, Q2 and Q3. And they're build largely in Q2 and Q3 because it takes a while to build them and ship them and put them into the hubs around the world. And they tend to build it ahead of the holiday season. And so that's one of the reasons why Q3 will tend to be larger and Q4 will tend to be more seasonal and Q1 will tend to be more seasonal than the past. But the end demand is fantastic. RTX is doing great. And part of it is just a result of the success of our notebooks. I'm going to hand it over to Colette.",445
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175538.0,Answer,Colette Kress,,Executives,29,"Yes. So with that from a background and you think about all those different components that are within gaming, the notebook, the overall Switch, and of course, all of the ray tracing that we have in terms of desktop, our normal seasonality, as we look at Q1 for gaming with all those 3 pieces, is usually sequentially down from Q4, sequentially down Q4 to Q1. This year, the outlook assumes it will probably be a little bit more pronounced due to the coronavirus. So in total, we're probably looking at Q1 to be in the low double-digit sequential decline in gaming.",101
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175539.0,Question and Answer Operator Message,Operator,,Operator,30,Your next question comes from the line of Atif Malik with Citi.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175540.0,Question,Atif Malik,,Analysts,31,"Good job on results and guide. On the same topic, coronavirus. Colette, I'm a bit surprised that the guidance -- the range on the guidance is not wider versus historic. Can you just talk about why not widen the range? And what went into that $100 million hit from the coronavirus?",51
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175541.0,Answer,Colette Kress,,Executives,32,"So Atif, thanks for the question. Again, it's still very early regarding the coronavirus. Our thoughts are out with both the employees, the families and others that are in China. So our discussions, both with our supply chain that is very prominent in the overall Asia region as well as our overall AIC makers as well as our customers, is as about as timely as we can be. And that went into our discussion and our thoughts on the overall guidance that we gave into our $100 million. We'll just have to see how the quarter comes through, and we'll discuss more when we get to it. But at this time, that was our best estimate at this time.",119
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175542.0,Question and Answer Operator Message,Operator,,Operator,33,Your next question comes from the line of William Stein with SunTrust.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175543.0,Question,William Stein,,Analysts,34,"Jensen, I'd love to hear your thoughts as to how you anticipate the inference market playing out. Historically, NVIDIA's had essentially all of the training market and little of the inference market in the last 1.5 years or so. I think that's changed where you've done much better in inference. Now you have the T4 in the cloud, you have EGX at the edge. And you have Jetson, I think, is what it's called at the sort of endpoint device. How do you anticipate that market for inference developing across those various positions? And how are you aligning your portfolio for that growth?",103
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175544.0,Answer,Jen-Hsun Huang,,Executives,35,"Yes. Thanks a lot, Will. Let's see, I think the -- historically, inference has been a small part of our business because AI was still being developed. Deep learning, AI is not -- historical AI, classical machine learning weren't particularly suited for GPUs and weren't particularly suited for acceleration. It wasn't until deep learning came along that the amount of computation necessary is just extraordinary. And the second factor is the type of AI models that were developed. Eventually, if -- the type of models related to natural language understanding and conversational AI and recommendation systems, these require instantaneous response. The faster the answer, the more likely someone is going to click on the answer. And so you know that latency matters a great deal, and it's measurable. The effect on the business is directly measurable. And so for conversational AI, for example, we've been able to reduce the latency of the entire pipeline from speech recognition to the language processing to, for example, fix the errors and such, come up with a recommendation to text to speech to the voice synthesis. That entire pipeline could take several seconds. We run it so fast that it's possible now for us to process the entire pipeline within a couple of hundred, 200, 300 milliseconds. That is in the realm of interactive conversation. 
Beyond that, it's just simply too slow. And so the combination of AI models that are large and complex that are moving to inference, moving to production. And then secondarily, conversational AI and latency-sensitive models and applications where our GPUs are essential, now moving forward, I think you're going to see a lot more opportunities for us in inference. 
The way to think about that long-term is acceleration is essential because of end of Dennard scaling. Process technology is going to demand that we compute in a different way. And the way that AI has evolved and deep learning, it suggests that acceleration on GPUs is just a really phenomenal approach. 
Data centers are going to have to be software-defined. And I think as I mentioned, I think I mentioned earlier to another question, I believe that in the future, the data center will all be accelerated. It will be all running AI models, and it will be software-defined and will be programmable and having an accelerated computing platform is essential. As you move out to the edge, it really depends on whether your platform is software-defined, whether it has to be programmable or whether it's fix functioned. There are many, many devices where the inference work is very specific. It could be something as simple as detecting changes in temperature or changes in sound or detecting motion. Those type of inference models are -- could still be based on deep learning. It's function-specific. You don't have to change it very often and you're running 1 or 2 models at any given point in time. And so those devices are going to be incredibly cost-effective. 
I believe, those AI chips, you're going to have AI chips that are $0.50, $1, and you're just going to put it into something and it's going to be doing magical detections. The type of platforms that we're in, such as self-driving cars and robotics, the software is so complicated and there's so much evolution to come yet, and it's going to constantly get better. Those software-defined platforms are really the ideal targets for us. And so we call it AI at the edge, edge computing devices. One of the edge computing devices I'm very excited about is what people call mobile edge or basically 5G telco edge. That data center will be programmable. We recently announced that we partnered with Ericsson and we're going to be accelerating the 5G stack. And so that needs to be a software-defined data center. It runs all kinds of applications, including 5G. And those applications are going to be -- those opportunities are fantastic for us.",659
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175545.0,Question and Answer Operator Message,Operator,,Operator,36,Your next question comes from the line of Mark Lipacis with Jefferies.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175546.0,Question,Mark Lipacis,,Analysts,37,"Jensen, I guess I had a question about your -- how you think about the sustainability of your market position in the data center? And I guess in my simplistic view, about 12 years ago, you made out a consensus call to invest in CUDA software, distribute it to universities. Neural networking took off and you were the de facto standard, and here we are right now. And for me, what's interesting to hear is that the demand that you're seeing today for your products is from markets that's just developed within the last year. And my question is like, how do you think about your investment, your R&D investment strategy to make sure that you are staying way ahead of the market, of the competition and even your customers who are investing in these markets, too?",137
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175547.0,Answer,Jen-Hsun Huang,,Executives,38,"Yes. Thanks, Mark. Our company has to live 10 years ahead of the market. And so we have to imagine where the world is going to be in 10 years' time, in 5 years' time and work our way backwards. Now our company is focused on one singular thing. The simplicity of it is incredible. And that one singular thing is accelerated computing, accelerated computing. And accelerated computing is all about the architecture, of course. It's about the complicated systems that we're in because throughput is high. When our acceleration, we can -- when we can compute 10x, 20x, 50x, 100x faster than the CPU, all of a sudden, everything becomes a bottleneck. Memory's a bottleneck, networking's a bottleneck, storage is a bottleneck, everything is a bottleneck. And so we have to be -- NVIDIA has to be a supremely good system designer. But the complexity of our stack, which is the software stack above it, is really where the investments over the course of the last -- some 29 years now, has really paid off. 
NVIDIA, frankly, has been an accelerated computing company since the day it was born. And so we -- our company is constantly trying to expand the number of applications that we can accelerate. Of course, computer graphics was an original one, and we're reinventing it with real-time ray tracing. We have rendering, which is a brand-new application that we're making great progress in. We just talked -- I just mentioned 5G acceleration. Recently, we announced genomics computing. And so those are new applications that are really important to the future of computing. 
In the area of artificial intelligence, from image recognition to natural language understanding, to conversation, to recommendation systems, to robotics and animation, the number of applications that we're going to accelerate in the field of AI is really, really broad. And each one of them are making tremendous progress and getting more and more complex. And so the question about the sustainability of our company really comes down to 2 dimensions. Let's assume for the fact -- let's assume for now that accelerated computing is the path forward, and we surely believe so. And there's a lot of evidence from the laws of physics to the laws of computer science that would suggest that accelerated computing is the right path forward. But this really basically comes down to 2 dimensions. One dimension is, are we continuing to expand? Are we continuing to expand the number of applications that we can accelerate? Whether it's AI or computer graphics or genomics or 5G, for example. And then the number -- and then the second is those applications, are they getting more impactful and adopted by the ecosystem, the industry? And are they continuing to be more complex? Those dimensions, the number of applications and the rich -- and the impact of those applications and the evolution, the growth of complexity of those applications, if those dynamics continue to grow, then I think we're going to do a good job. We're going to sustain. And so -- and I think when I spelled it out that way, it's basically the equation of growth of our company. I think it's fairly clear that the opportunities are fairly exciting ahead.",543
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175548.0,Question and Answer Operator Message,Operator,,Operator,39,Your next question comes from the line of Blayne Curtis with Barclays.,12
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175549.0,Question,Blayne Curtis,,Analysts,40,"Jensen, I just wanted to ask you on the auto side. I think at least one of your customers might have slowed out their program. Just kind of curious as you look out the next couple of years, the challenges, if the OEM is moving slower? And then just any perspective on the regulatory side, has anything changed there, would be helpful.",62
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175550.0,Answer,Jen-Hsun Huang,,Executives,41,"I think that the automotive industry is struggling, but -- for all of the reasons that everybody knows. However, the enthusiasm to redefine and reinvent their business model has never been greater. Every single one of them, every single one of them would know now and they surely -- they've known for some time, and autonomous capabilities is really the vehicle to do that. They need to be tech companies. Every car company wants to be a tech company. They need to be a tech company. Every car company needs to be software-defined. And the platform by which to do so is an electric vehicle with autonomous autopilot capability. That car has to be software-defined. And this is their future and they're racing to get there. And so although the automotive industry is struggling in near term, their opportunity has never been better in my opinion. The future of AV is more important than ever. The opportunity is very real. The benefits of autonomous is for whether it's safety, whether it's utility, whether it's cost reduction and productivity, has never been more clear. And so I think that I'm as enthusiastic as ever about the autonomous vehicles and the projects that we're working on are moving ahead. And so the near-term challenges of the automotive industry or whatever sales slowdown in China that they're experiencing, I feel badly about that. But the industry is as clearheaded about the importance of AV as ever.",243
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175551.0,Question and Answer Operator Message,Operator,,Operator,42,I will now turn the call back over to Jensen for any closing remarks.,14
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175552.0,Answer,Jen-Hsun Huang,,Executives,43,"We had an excellent quarter with strong demand for NVIDIA RTX graphics and NVIDIA AI platforms and record data center revenue. NVIDIA RTX is reinventing computer graphics, and the market's response is excellent, driving a powerful upgrade cycle in both gaming and professional graphics, while opening whole new opportunities for us to serve the huge community of independent creative workers and social content creators and new markets in rendering and cloud gaming. Our data center business is enjoying a new wave of growth, powered by 3 key trends in AI, natural language understanding, conversational AI, deep recommenders, are changing the way people interact with the Internet. The public cloud demand for AI is growing rapidly. And as AI shifts from development to production, our inference business is gaining momentum. We'll be talking a lot more about these key trends and much more at next month's GTC Conference in San Jose. Come join me. You won't be disappointed. Thanks, everyone.",159
32307.0,"NVIDIA Corporation, Q4 2020 Earnings Call, Feb 13, 2020",2020-02-13,48.0,Earnings Calls,NVIDIA Corporation,3599.0,1912480.0,75175553.0,Question and Answer Operator Message,Operator,,Operator,44,"Ladies and gentlemen, this concludes today's conference call. Thank you for participating. You may now disconnect.",16
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334109.0,Presentation Operator Message,Operator,,Operator,0,"Good afternoon. My name is Josh, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's Financial Results Conference call. [Operator Instructions] Thank you. 
Simona Jankowski, you may begin your conference.",40
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334110.0,Presenter Speech,Simona Stefan Jankowski,,Executives,1,"Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the first quarter of fiscal 2021. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the second quarter of fiscal 2021. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent.  
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may vary materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent Form 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, May 21, 2020, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.  
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website.  
With that, let me turn the call over to Jensen.",254
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334111.0,Presenter Speech,Jen-Hsun Huang,,Executives,2,"Thanks, Simona. Before Colette describes our quarterly results, I'd like to thank those who are on the front lines of this crisis, first responders, health care workers, service providers, who inspires every day with their bravery and selflessness. I also want to acknowledge the incredible efforts of our colleagues here at NVIDIA. Despite many challenges, they have barely broken stride during one of the busiest periods in our history.  
Our efforts related to the virus are focused in 3 areas. First, we're taking care of our families and communities. We've pooled in raises by 6 months to put more money in our employees' hands, and NVIDIA and our people have donated thus far more than $10 million to those in need.  
Second, we're using NVIDIA's unique capabilities to fight the virus. A great deal of science being done on COVID-19 uses NVIDIA technology for acceleration when every second counts. Some of the many examples, including sequencing the virus, analyzing drug candidates, imaging the virus at molecular resolution with cryo-electron microscopy and identifying elevated body temperature with AI cameras.  
And third, because COVID-19 won't be the last killer virus, we need to be ready for the next outbreak. NVIDIA technology is essential for the scientific community to develop an end-to-end computational defense system, a system that can detect early, accelerate the development of a vaccine, contain the spread of disease and continuously test and monitor.  
We are racing to deploy the NVIDIA Clara computational health care platforms, Clara Parabricks can accelerate genomics analysis from days to minutes. Clara Imaging will continue to partner with leading research institutes to develop state-of-the-art AI models to detect infections, and Clara Guardian will connect AI to cameras and microphones and hospitals to help overloaded staff watch over patients.  
We completed the acquisition of Mellanox on April 27. Mellanox is now NVIDIA's networking brand and business unit and will be reported as part of our data center market platform, and Israel is now one of NVIDIA's major technology centers.  
The new NVIDIA has a much larger footprint in data center computing, end-to-end and full-stack expertise in data center architectures and tremendous scale to accelerate innovation. NVIDIA Mellanox are a perfect combination and position us for the major forces shaping the IT industry today, data center scale computing and AI.  
From micro service cloud applications to machine learning and AI, accelerated computing and high-performance networking are critical to modern data centers. Previously, a CPU compute node was the unit of computing. Going forward, the new unit of computing is an entire data center. The basic computing elements are now storage servers, CPU servers and GPU servers, and are composed and orchestrated by hyperscale applications that are serving millions of users simultaneously. Connecting these computing elements together is the high-performance Mellanox networking. This is the era of data center scale computing. And together, NVIDIA Mellanox can architect end to end. Mellanox is an extraordinary company, and I'm thrilled that we're now one force to invent the future together.  
Now let me turn the call over to Colette.",509
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334112.0,Presenter Speech,Colette Kress,,Executives,3,"Thanks, Jensen. Against the backdrop of the extraordinary events unfolding around the globe, we had a very strong quarter. Q1 revenue was $3.08 billion, up 39% year-on-year, down 1% sequentially and slightly ahead of our outlook, reflecting upside in our data center and gaming platforms.  
Starting with gaming. Revenue of $1.34 billion was up 27% year-on-year and down 10% sequentially. We are pleased with these results, which exceeded expectations in the quarter, marked by the unprecedented challenge of the COVID-19.  
Let me give you some color. Early in Q1, as the epidemic unfolded, demand in China was impacted with iCafes closing for an extended period. As the virus spread globally, much of the world started working and learning from home, and gameplay surged. Globally, we have seen 50% rise in gaming hours played on our GeForce platform, driven both by more people playing and more gameplay per user.  
With many retail outlets closed, demand for our products has shifted quite efficiently to e-tail channels globally. Gaming laptops revenue accelerated to its fastest year-on-year growth in 6 quarters. We are working with our OEMs, channel partners to meet the growing needs of the professionals and students engaged in working, learning and playing at home. In early April, our global OEM partners announced a record new 100 NVIDIA GeForce-powered laptops with availability starting in Q1 and the most to ship in Q2. These laptops are the first to use our high-end GeForce RTX 2080 SUPER and 2070 SUPER GPUs, which have been available for desktop since last summer.  
In addition, OEMs are bringing to market laptops based on the RTX 2060 GPU at just $999, a price point that enables a larger audience to take advantage of the power and features of RTX, including its unique ray tracing and AI capabilities. These launches are well-timed as mobile and remote computing needs accelerate.  
The global rise in gaming also lifted sales of NVIDIA Nintendo Switch and our console business, driving strong growth both sequentially and year-over-year. We collaborated with Microsoft and Mojang to bring RTX ray tracing to Minecraft, the world's most popular game with over 100 million gamers monthly and over 100 billion total views on YouTube. Minecraft with RTX looks astounding with realistic shadows and reflections. Light that reflects, refracts and scatters through surfaces as naturalistic effects like fog. Reviews for it are off the charts. Ars Technica called it a jaw-dropping stunner, and PC World said it was glorious to behold.  
Our RTX technology stands apart, not only with our 2-year lead in ray tracing but with its use of AI to speed up and enhance games using the Tensor Core silicon on our RTX class GPUs. We introduced the next version of our AI algorithm called Deep Learning Super Sampling. In real time, DLSS 2.0 can fill the missing bits from every frame, doubling performance. It represents a major step function from the original, and it can be trained on nongaming-specific images, making it universal and easy to implement.  
The value and momentum of our RTX GPUs continue to grow. We have a significant upgrade opportunity over the next year with the rise and tide of RTX-enabled games, including major blockbusters like Minecraft and Cyberpunk. Let me also touch on our game streaming service, GFN, which exited beta this quarter. It gives gamers access to more than 650 games with another 1,500 in line to get onboarded. These include Epic Games, Fortnite, which is the most played game on GFN; and other popular titles such as CONTROL, Destiny 2 and League of Lighting in the fall. Since launching in February, GFN has added 2 million users around the world, with both sign-ups and hours of gameplays boosted by stay-at-home measures. GFN expands our market reach to the billions of gamers with underpowered devices. It is the most publisher-friendly, developer-friendly game streaming service with the greatest number of games and the only one that supports ray tracing.  
Moving to Pro Visualization. Revenue was $307 million, up 15% year-on-year and down 7% sequentially. Year-on-year revenue growth accelerated in Q1 driven by laptop workstations and Turing adoption.  
We are seeing continued momentum in our ecosystem for RTX ray tracing. We now have RTX support for all major rendering visualization and design software packages, including Autodesk Maya, Dassault's CATIA, Pixar's RenderMan, Chaos Group's V-Ray and many others. Autodesk has announced that the latest release of VRED, its automotive 3D visualization software, supports NVIDIA RTX GPUs. This enables designers to take advantage of RTX to produce more like-life designs in a fraction of the time versus CPU-based systems. Over 45 leading creative and design applications now take advantage of RTX, driving a sustained upgrade opportunity for Quadro-powered systems while also expanding their reach.  
We see strong demand in verticals, including health care, media and entertainment and higher education, among others. Higher health care demand was fueled in part by COVID-19 related research at Siemens, Oxford and Caption Health. Caption Health received FDA clearance for an update to its AI-guided ultrasound, making it easier to perform diagnostics-quality cardiac ultrasounds. And in media and entertainment, demand increased as companies like Disney deployed remote workforce initiatives.  
Turning to automotive and robotic autonomous machines. Automotive revenue was $155 million, down 7% year-on-year and down 5% sequentially. The automotive industry is seeing a significant impact from the pandemic, and we expect that to affect our revenue in the second quarter as well, likely declining about 40% from Q1.  
Despite the near-term challenges, our important work continues. We believe that every machine that moves someday will have autonomous capabilities. During the quarter, Xpeng introduced the P7, an all-electric sports sedan with innovative Level 3 automated driving features, powered by the NVIDIA DRIVE AGX Xavier AI compute platform. Our open, programmable, software-defined platform enables Xpeng to run its proprietary software while also delivering over-the-air updates for new driving features and capabilities. Production deliveries of the P7 with NVIDIA DRIVE begin next month.  
Our Ampere architecture will power our next-generation NVIDIA DRIVE platform called Orin, delivering more than 6x the performance of Xavier Solutions and 4x better power efficiency. With Ampere scalability, the DRIVE platform will extend from driverless robotaxis all the way down to in windshield driver assistant systems sipping just a few watts of power. Customers appreciate the top-to-bottom platform all based on a single architecture, letting them build one software-defined platform for every vehicle in their fleet.  
Lastly, in the area of robotics, we announced that BMW Group has selected the new NVIDIA as a robotics platforms to automate their factories, utilizing logistic robots built on advanced AI computing and visualization technologies.  
Turning to data center. Quarterly revenue was a record $1.14 billion, up 80% year-on-year and up 18% sequentially, crossing the $1 billion mark for the first time. Announced last week, the A100 is the first Ampere architecture GPU. Although just announced, A100 is in full production, contributed meaningful to Q1 revenue and demand is strong. Overall, data center demand was solid throughout the quarter. It was also broad-based across hyperscale and vertical industry customers as well as across workloads, including training, inference and high-performance computing. We continue to have solid visibility into Q2.  
The A100 offers the largest leap in performance to date over our 8 generations of GPUs, boosting performance by up to 20x over its predecessor. It is exceptionally versatile, serving as a universal accelerator for the most important high-performance workloads, including AI training and inference as well as data analytics, scientific computing and cloud graphics.  
Beyond its leap performance and versatility, the A100 introduces new elastic computing technologies that make it possible to bring rightsized computing power to every job. A multi-instance GPU capability allows each A100 to be partitioned into as many as 7 smaller GPU instances. Conversely, multiple A100 interconnected by our third-generation NVLink can operate as one giant GPU for ever larger training tasks. This makes the A100 ideal for both training and for inference. The A100 will be deployed by the world's leading cloud service providers and system builders, including Alibaba cloud, Amazon Web Services, Baidu Cloud, Dell Technologies, Google Cloud platform, HPE and Microsoft Azure, among others. It is also getting adopted by several supercomputing centers, including the National Energy Research Scientific Computing Center and the Jlich Supercomputing Centre in Germany and Argonne National Laboratory.  
We launched and shipped the DGX A100, our third-generation DGX and the most advanced AI system in the world. The DGX A100 is configurable from 1 to 56 independent GPUs to deliver elastic software-defined data center infrastructure for the most demanding workloads from AI training and inference to data analytics.  
We announced 2 products for edge AI: the EGX A100 for larger commercial off-the-shelf servers; and the EGX Jetson Xavier NX for micro-edge servers. Supported by full AI optimized cloud, native and secure software, the EGX platform is built for AI computing at the edge. With the EGX, hospitals, retail stores, farms and factories can securely carry out real-time processing of the massive amounts of data streaming from trillions of edge sensors. NVIDIA EGX makes it possible to securely, deploy and manage and update fleets of servers remotely. EGX is also ideal for the massive computational challenge of 5G networks, which we are working on with our partners like Ericsson and Mavenir.  
Additionally, we announced CUDA 11 and other important software harnessing the A100's performance and universatility (sic) [ universality ] to accelerate 3 of the most complex and fast-growing workloads: recommendation systems, conversational AI and data science.  
First, NVIDIA Merlin is a deep recommendator (sic) [ recommender ] application framework that enables developers to quickly build state-of-the-art recommendation systems, leveraging our pretrained models. With billions of users and trillions of items on the Internet, deep recommendators are the critical engine powering virtually every internet service.  
Second, NVIDIA Jarvis is a GPU-accelerated application framework that makes it easy for developers to create, deploy and run end-to-end real-time conversational AI applications that understand terminology unique to each company and its customers using both vision and speech. Demand for these applications are surging. Amid the shift to working from home, telemedicine and remote learning.  
And third, in the field of data science and data analytics, we announced that we are bringing end-to-end GPU acceleration to Apache Spark, an analytics engine for big data processing that uses more than 500,000 data scientists worldwide. Native GPU acceleration for the entire Spark pipeline, from extracting, transforming and loading the data to training to inference, delivers the performance and the scale needed to finally connect the potential of big data with the power of AI. Adobe has achieved a 7x performance improvement and a 90% cost savings in an initial test using GPU-accelerated data analytics with Spark.  
Our accelerated computing platform continues to gain momentum, underscored by the tremendous success of GTC Digital, our annual GPU technology conference, which shifted this spring to an online format. More than 55,000 online developers and AI research registered for the online event, which includes hundreds of hours of free content from AI practitioners and industry experts who leverage NVIDIA's platforms.  
Our ecosystem is now 1.8 million developers strong. Times like these truly test a computing platform's metal in the utility it brings to scientist racing for solutions. Researchers around the world are deploying our GPU computing platform in the fight against COVID-19. Scientists are combining AI simulation to detect changes in pneumonia cases, sequence, the virus and seek effective biomolecular compounds for a vaccine or treatment.  
The first breakthrough came from researchers at the University of Texas at Austin and National Institute of Health, who used the GPU-accelerated application to create the first 3D atomic scale map of virus using NVIDIA GPUs. This was followed by researchers at Oak Ridge National Laboratory who screened 8,000 compounds to identify 77 promising drug targets using the world's fastest supercomputer, Summit, which is powered by more than 27,000 NVIDIA GPUs.  
The V100 GPUs at Oak Ridge are in high demand as they can analyze 17 million compound protein combinations in a day. They'll help understand the virus spread pattern, the University of California, San Diego, researchers ported their microbiomic analysis software to GPUs in the San Diego supercomputing cluster of 500x analysis speed up from what some people are more susceptible to the virus.  
Okay. Moving to the rest of the P&L. Q1 GAAP gross margins was 65.1% and non-GAAP was 65.8%, up sequentially and year-on-year, primarily driven by GeForce GPU product mix and higher data center sales. Q1 GAAP operating expenses were $1.03 billion, and non-GAAP operating expenses were $821 million, up 10% and 9% year-on-year, respectively. Q1 GAAP EPS was $1.47, up 130% from a year earlier, and non-GAAP EPS was $1.80, up 105% from a year ago. Q1 cash flow from operations was $909 million.  
Before I turn to the outlook, let me make a few comments on our Mellanox acquisition. Beyond the strong strategic and cultural fit that Jensen has discussed, Mellanox has exceptionally strong financial profile. The company reported revenue of $429 million in its March quarter, accelerating to 40% year-on-year growth, with GAAP and non-GAAP gross margins in the mid- to high 60% range. We expect the acquisition to be immediately accretive to non-GAAP gross margins, non-GAAP earnings per share and free cash flow. We aim to retain the full Mellanox team and accelerate investments in our combined road map as we jointly innovate on our shared vision for the future of accelerated computing.  
With that, let me turn to the outlook of the second quarter of fiscal 2021, which includes a full quarter contribution from Mellanox. We have assumed in our outlook the potential ongoing impact from COVID-19. We expect our automotive platform sales to be down 40% on a sequential basis and Pro Viz to decline sequentially. In gaming, while we will likely see ongoing impact from the partial operations or closures of iCafes and retail stores, we expect that to be largely offset by a shift to e-tail channels. Overall, the precise magnitude of the impact is difficult to predict, given uncertainties around the reopening of the economy. Overall, we expect second quarter revenue to be $3.65 billion, plus or minus 2%. The contribution of Mellanox revenue is likely to be in the low teens percentage range of our total Q2 revenue. We are providing this breakout to help with comparability between Q1 and Q2. But going forward, it will become an integrated part of our data center market platform.  
GAAP and non-GAAP gross margins are expected to be 58.6% and 66%, respectively, plus or minus 50 basis points. The sequential decline in GAAP gross margins primarily reflects an increase in acquisition-related costs, most of which are nonrecurring.  
GAAP and non-GAAP operating expenses are expected to be approximately $1.52 billion, and $1.04 billion, respectively. The sequential change in GAAP operating expenses reflects an increase in stock-based compensation and acquisition-related costs. GAAP and non-GAAP operating expenses for the full year are expected to be approximately $5.7 billion and $4.1 billion, respectively. For the full year, stock-based compensation and acquisition-related costs also influence.  
GAAP and non-GAAP OI&E are both expected to be an increase of approximately $50 million and $45 million, respectively. GAAP and non-GAAP tax rates are both expected to be 9%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $225 million to $250 million. Further financial details are included in the CFO commentary and other information available on our IR website.  
New this quarter, we have also posted an investor presentation summarizing our results and key highlights. In closing, let me highlight upcoming events for the financial community. Next Thursday, May 28, we will webcast a presentation and Q&A with Jensen on our recent product announcement moderated by Evercore. We will also be at Cowen's TMT Conference on May 27; Morgan Stanley's Cloud Secular Winners Conference on June 1; BoFa's Technology Conference on June 2; Needham's Fourth Automotive Technology Conference on June 3 and Nasdaq Investor Conference on June 16.  
Operator, we will now open for questions. Can you please poll for questions, please.",2683
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334113.0,Question and Answer Operator Message,Operator,,Operator,4,[Operator Instructions] Aaron Rakers with Wells Fargo.,7
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334114.0,Question,Aaron Rakers,,Analysts,5,"Congratulations on a solid quarter. Colette, I'm curious of your commentary around visibility in the data center side, that that's comments over the last couple of quarters, how would you characterize your visibility today relative to maybe what it was last quarter? And how do we think about the visibility in the context of trends maybe into the back half of the calendar year.",64
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334115.0,Answer,Colette Kress,,Executives,6,"Thanks, Will, for the question. You are correct. We have indicated a couple of quarters ago that we were starting to see improved visibility after we came out of the digestion period in the prior overall fiscal year. As we move into Q2, we still have visibility and solid visibility into our Q2 results for overall data centers. So at this time, I'd say they are relatively about the same of what we had seen going into the Q1 period. And we think that is a true indication of their excitement about our platform and most particularly our excitement regarding A100, and that's launched and its additional products. 
Now regarding the second half of the year, as you know, we have seen broad-based growth in both the hyperscale and the vertical industries, both of them in terms of at record levels. In our Q1 results. And we see in terms of inferencing continuing to grow as well, as well as we're also expanding in terms of edge AI. Our strong demand of the A100 products, including the Delta Board, but also in terms of our DGXs, was just starting an initial ramp. However, we do guide only 1 quarter at a time. So it's still a little bit too early for us to give a true certainty in terms of the macro situation that's in front of us. But again, we feel very good about the demand for A100.",239
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334116.0,Question and Answer Operator Message,Operator,,Operator,7,Your next question comes from Stacy Rasgon with Bernstein Research.,10
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334117.0,Question,Stacy Rasgon,,Analysts,8,"I first wanted to follow-up on your gaming commentary. You sort of mentioned a couple of offsets. COVID potentially still a headwind, e-tail or tailwind and maybe offsetting each other. Were you trying to suggest that those did offset completely and gaming was kind of flattish into Q2? Because I know it has a typical seasonal pattern switches typically up. I guess what were you trying to say with those kind of factors? And what are the kinds of things we should be thinking about when it comes to seasonality, Colette, into Q2 around that business segment?",98
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334118.0,Answer,Colette Kress,,Executives,9,"So let me start, and I'll see if Jensen also wants to add on to it. I think you're talking about our sequential between Q1 and Q2. Some of the...",30
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334119.0,Question,Stacy Rasgon,,Analysts,10,Yes. That's right.,3
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334120.0,Answer,Colette Kress,,Executives,11,"Right. Some of the pieces that we had seen related to COVID-19 in Q1 may carry over into Q2. COVID-19, in fact, had an impact in terms of our retail channels as well as our iCafes. However, as we discussed, efficiently, moved to overall e-tail. We have normally been seasonally down in desktop between Q1 and Q2, and that will likely happen. But we do see the strength in terms of laptops and overall consoles as we move for Q1 to Q2. So in summary, we do expect grow sequentially between Q1 and Q2 for our overall gaming business. And I'll turn it over to Jensen to see if he has additional commentary.",113
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334121.0,Answer,Jen-Hsun Huang,,Executives,12,"No, that was great. That was fantastic.",7
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334122.0,Question,Stacy Rasgon,,Analysts,13,"Yes. I guess just to follow up on that, though, if it's growing. I mean like in prior years, we've seen it grow like very strong double digits. Obviously, the mix of the business was different back then. But do you think that the kind of -- I mean are we thinking kind of it's up somewhat? You don't -- is there any chance that it could be up like on -- for what we've seen in terms of like typical levels in the past? Like can you give us any sense of magnitude, that would be really helpful?",99
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334123.0,Answer,Colette Kress,,Executives,14,"Yes. I think when we think about that sequential growth, we'll probably be in the low -- moving up to probably the mid-single digits in terms of -- that's what our guidance right now, and we'll just have to see how the quarter goes.",44
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334124.0,Question,Stacy Rasgon,,Analysts,15,Yes. That's very helpful.,4
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334125.0,Answer,Jen-Hsun Huang,,Executives,16,"Stacy, the thing that I would add is this. I would say, I think the guidance is exactly what Colette mentioned. But if you look at the big picture, there's a few dynamics that are working really well in our favor. First, of course, is that RTX and ray tracing is just the home run. Minecraft was phenomenal. We have 33 games in the pipe that has already been announced or shipping. Just about every game developers signed on to RTX and ray tracing, and I think it's a foregone conclusion that this is the next generation. This is the way computer graphics is going to be in the future. And so I think RTX is a home run. 
The second, the notebooks that we create is just doing great. We got 100 notebooks in gaming. We have 75 notebooks designed for either mobile workstations or what we call NVIDIA studio for designers and creators. And the timing was just perfect. With everybody needing to stay at home, the ability to have a mobile gaming platform and a mobile workstation, it was just perfect timing. And then, of course, you guys know quite well that our Nintendo Switch is doing fantastic. There are 3 -- the top 3 games in the world. The top games in the world today are Fortnite, Minecraft and Animal Crossing. All 3 games are NVIDIA platforms. And so I think we have all the dynamics working in our favor. And then we just got to see how it turns out.",255
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334126.0,Question and Answer Operator Message,Operator,,Operator,17,Your next question comes from Joe Moore with Morgan Stanley.,10
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334127.0,Question,Joseph Moore,,Analysts,18,"I wanted to ask about the rollout of Ampere how quickly does that roll in the various segments between hyperscale as well as on the DGX side as well as on the HPC side. And is it a smooth transition? Is there -- I remember when you launched Volta, there was a little bit of a transitional pause. Just can you tell us how you see that ramping up with the different customer segments?",74
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334128.0,Answer,Jen-Hsun Huang,,Executives,19,"Yes. Thanks a lot, Joe. So first of all, taking a step back. Accelerated computing is now common sense in data centers. It wasn't the case when we first launched Volta. If you went back to Volta, Volta was the first generation that the deep learning training in a really serious way, and it was really focused on training. It was focused on training and high-performance computing. We didn't come until later with the inference version called T4. 
But over the course of the last 5 years, we've been accelerating workloads that are now diversifying in data centers. If you take a look at most of the hyperscalers, machine learning is now pervasive. Deep learning is now pervasive. The notion of accelerated deep learning and machine learning using our GPUs is now common sense. It didn't used to be. People still saw it as something esoteric. But today, data centers all over the world expect a very significant part of their data center being accelerated with GPUs. The number of workloads that we've accelerated since in the last 5 years have expanded tremendously, whether it's imaging or video or conversational AI or deep recommender systems that probably unquestionably, at this point, the most important machine learning model in the world. And so the number of applications we now accelerate is quite diverse. And so that's really -- that's contributed greatly to the ramp of Ampere. When we came -- when we started to introduce Ampere to the data center, it was very commonsensical to them that they would adopt it. They have a large amount of workload that's already accelerated by NVIDIA GPUs. 
And as you know, our GPUs are architecturally compatible from generation to generation. We're forward compatible or backwards compatible. Everything that runs on T4 runs on A100, everything that runs on V100 runs on A100. And so I think the transition is going to be really, really smooth. On the other hand, because V100 and T4 -- which, by the way, V100 and T4 had a great quarter. It was sequentially up. And then on top of that, we grew with the A100 shipment. A100 -- or excuse me, V100 and T4 are now quite broadly adopted in hyperscalers for their AI services, in cloud computing, in a vertical industries, which is almost roughly half of our overall HPC business. All the way out to the edge, which had a great quarter. Much smaller part, of course -- supercomputing is important, but it's a very small part of the high-performance computing. But that's also -- we also shipped A100 to supercomputing centers. And so I think the general sense of it -- the summary of it is that the number of workloads for accelerated computing has continued to grow, the adoption of machine learning and AI and all the cloud and hyperscalers has grown. The common sense of using acceleration is now a foregone conclusion. And so I think we're ramping into a very receptive market with a really fantastic -- with a really fantastic product.",509
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334129.0,Question and Answer Operator Message,Operator,,Operator,20,Your next question comes from Vivek Arya with Bank of America.,11
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334130.0,Question,Vivek Arya,,Analysts,21,"Congratulations on the strong growth and execution. Just a quick clarification. Colette, 66% kind of the new baseline for gross margin? And then the question, Jensen, for you, is give us a sense for how much inference as a workload and payer as a product are expected to contribute? I'm just curious where you are in terms of growing in the inference and edge AI market? And where are we kind of in the journey of Ampere penetration?",78
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334131.0,Answer,Colette Kress,,Executives,22,"So let me start on the first question regarding the gross margin and our gross margin as we look into Q2. We are guiding Q2 non-GAAP gross margins at 66%. This is -- would be another record gross margin quarter just as we finished an overall record level, even as we are continuing right now to ramp our overall Ampere architecture within that. The Q2 also incorporates Mellanox. Mellanox has a very similar overall margins to our overall data center margins as well. But we see this new baseline as a great transition and likely to see some changes as we go forward. However, it's still a little early to see where these gross margins will go. But we're very pleased with the overall guidance right now at 66% for Q2.",131
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334132.0,Answer,Jen-Hsun Huang,,Executives,23,"Accelerated computing is just at the beginning of its journey. If you look at -- I would characterize it as several segments. First is hyperscaler AI microservices, which is all the services that we enjoy today that has AI. Whenever you shop on the web, it recommends a product. When you're watching a movie, it recommends a movie or it recommends a song. All of those -- or recommends news or recommends a friend or recommends a website, the first 10 websites that they recommend. All of these recommenders that are powering the Internet are all based on machine learning today. It's the reason why they're collecting so much data. The more data they can collect, the more they could predict your preference, and that predicting your preference is the core to a personalized Internet. It used to be largely based on CPU approaches. But going forward, it's all based on deep learning approaches. The results are much more superior and a few percentage change in preference prediction accuracy could result in tens of billions of dollars of economics. 
And so this is very, very big deal. And the shift towards deep learning in hyperscale micro services or AI micro services is still ramping. Second is cloud. And as you know, cloud is a $100 billion market segment of it today, growing about 40% into $1 trillion opportunity. This -- cloud computing is the single largest IT industry transformation that we have ever seen. The 2 powers that is really -- the force -- the 2 forces that is really driving our data center business is AI and cloud computing. We're perfectly, perfectly positioned to benefit from these 2 powerful forces. So the second is cloud computing. And that journey is -- has a long ways to go. Then the third is industrial edge. In the future, today -- it's not the case today. But the combination of IoT, 5G, industrial 5G and artificial intelligence, it's going to turn every single industry into a tech industry. And whether it's logistics or warehousing or manufacturing or farming, construction, industrial, every single industry will become a tech industry. And there'll be trillions of sensors, and they'll be connected to little micro data centers. 
And those data centers will be in the millions. They'll be distributed all over the edge. And that journey has just barely started. We announced 3 very important partners in 3 domains. And they're the lead partners that we felt that people would know, but we have several hundred partners that are working with us on edge AI. We announced Walmart for smart retail. We announced the U.S. Postal Service, the world's largest mail sorting service and logistics service. And then we announced this last quarter, BMW, who is working with us to transform their factory into a robotics, automated factory of the future. And so these 3 applications are great examples of the next phase of artificial intelligence and where Ampere is going to ramp into. And that is just really at its early stages. And so I think it's fair to say that we're really well positioned in the 2 fundamental forces of IT today, data center scale computing and artificial intelligence. And the segments that it's going to make a real impact are all gigantic markets. Hyperscale AI, cloud and edge AI.",556
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334133.0,Question and Answer Operator Message,Operator,,Operator,24,Your next question comes from C.J. Muse with Evercore.,10
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334134.0,Question,Christopher Muse,,Analysts,25,"I guess if I could ask 2. Colette, can you help us with what you think the growth rate for Mellanox could look like in calendar '20? And then Jensen, a bigger picture question for you and really not specific to health care, more broad-based. But how do you think about the long-lasting impact of COVID on worldwide demand for AI?",61
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334135.0,Answer,Colette Kress,,Executives,26,"C.J., can you help me? You cut out in the middle of your sentence to me. Can you repeat the first part of it for me?",27
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334136.0,Question,Christopher Muse,,Analysts,27,"No, sorry about that. I'm curious if you could provide a little handholding on what we should think about for growth for Mellanox in calendar '20?",26
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334137.0,Answer,Colette Kress,,Executives,28,"At this time, it's a little early for us. And as you know, we generally just go 1 quarter out, and we're excited to bring the Mellanox team on board so we can start beginning the future of building products together. For the overall margin, their overall performance over the last couple of quarters, they had a great last year. They had a great March quarter as well. And we're just going to have to stay tuned to see equally with them what the second half of the year looks for them. Okay?",93
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334138.0,Answer,Jen-Hsun Huang,,Executives,29,"Yes, C.J., thanks for the question. This pandemic is really quite tragic, and it's reshaping industries and markets. And I think it's going to be structural. I think it's going to remain. And I think your question is really good because now it's a good time to think about where to double down. There's a few areas that I believe are going to be structurally changed. And I think that once I say it, it'll be very sensible. The first is that the world's enterprise digital transformation and moving to the cloud, that is going to accelerate. Every single company can't afford to rely just on on-prem IT. They have to be much more resilient. And having a hybrid cloud computing infrastructure is  going to provide them the resilience they need. And so that's one. And when the world moves and accelerates into this $1 trillion IT infrastructure transformation, which is now $100 billion into that journey, it's growing 40% a year, I wouldn't be surprised to see that accelerate. And so cloud computing AI is going to accelerate because of that. The second is the importance of creating a computational defense system. The defense systems of most nations today are based on radar. And yet in the future, our defense systems are going to detect things that are unseeable. It's going to be infectious disease. 
And I think every nation and government and scientific lab is now gearing up to think about what does it take to create a national defense system for each country that is based on computational methods? And NVIDIA is an accelerated computing company. We take something that otherwise would take a year in the case of Oak Ridge, and they filter 1 billion compounds in a day. And that's what you need to do. You need to find a way to have an accelerated computational defense system that allows you to find insight, detect early warning ASAP. And then, of course, the computational system has to go through the entire range from mitigation to containment to living within the monitoring. And so scientific labs are going to be gearing up. National labs are going to be gearing up. The third part is AI and robotics. We're going to have to have the ability to be able to do our work remotely. 
NVIDIA has a lot of robots that are helping us in our labs. And without those robots helping us in our labs, we'll have a hard time getting our work done. And so we need to have remote autonomous capability for -- to handle all of these -- either dangerous circumstances to disinfect environments, to fumigate environments autonomously, to clean environments, to be able to interact with people where as little as possible in the event of an outbreak. All kinds of robotics applications are being dreamed up right now to help society forward in the case of another outbreak. And then lastly, I think more and more people are going to work permanently from home. There's a strong movement of companies that are going to support a larger percentage of people working from home. And when people work from home, it's going to clearly increase the single best home entertainment, which is video games. I think video games is going to represent a much larger segment of the overall entertainment budget of society. 
And so these are some of the trends, I would say. I would say cloud computing, AI. I would say national labs, a computational defense system, robotics and working from home are structural changes that are going to be here to stay. And these dynamics are really good for us.",611
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334139.0,Question and Answer Operator Message,Operator,,Operator,30,Your next question comes from Toshiya Hari with Goldman Sachs.,10
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334140.0,Question,Toshiya Hari,,Analysts,31,"I had one for Colette and then one for Jensen as well, if I may. Colette, I wanted to come back to the gross margin question. You're guiding July essentially flat sequentially, despite what I'm guessing is better mixed with non-ops coming in and automotive guided down 40% sequentially. I guess the question is, what are some of the offsets that are pulling down gross margins in the current quarter? And sort of related to that, how should we be thinking about the cadence and OpEx going forward, given the 6-month pull in that you guys talked about on the compensation side? And then one quick one for Jensen. I was hoping you could comment on the current trade landscape between the U.S. and China. I feel like you guys shouldn't be impacted in a material way directly nor indirectly. But at the same time, given the critical role you play in scientific computing, I can sort of see a scenario where some people may claim that you guys contribute to efforts outside of the U.S. So if you can kind of speak on that -- speak to that, that will be helpful.",193
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334141.0,Answer,Colette Kress,,Executives,32,"Thanks, Toshiya, for your question. So regarding our gross margins in the second quarter, our second quarter guide at 66% is up sequentially from even a record level in terms of what we had in terms of Q1. This next record that we hope to achieve with our overall guidance is even with including our overall Ampere architecture. So typically, when we transition to a new architectures, margins can somewhat be a little bit lower on the onset but tend to kind of move up and trend up over time. Additionally, as you articulated, our automotive is lower. But also, we're going to see growth in some of our platforms in gaming such as consoles, which may offset those 2. But overall, there's nothing structural to really highlight other than our mix in business and the ramp of Ampere and its transition.",142
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334142.0,Answer,Jen-Hsun Huang,,Executives,33,"Let's see, the trade tension. We've been living in this environment for some time, Toshiya. And as you know, the trade tension has been in the background for coming up on a year, probably gotten longer. And China's high-performance computing systems are largely based on Chinese electronics anyhow. And so that's -- I think our condition won't materially change going forward.",62
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334143.0,Answer,Colette Kress,,Executives,34,"So Toshiya, let me respond to your second question that you had for me, which was regarding to our OpEx and our decision to pull forward our overall local into Q2. This is something that we've normally done later in the year. We felt it was prudent during the current COVID-19. Although our employees are quite safe. We just wanted to make sure that their family members also were safe and had the opportunity to have cash upfront. It is about a couple of months, about 4 months earlier than normal, and it is incorporated in our guidance for Q2.",100
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334144.0,Question and Answer Operator Message,Operator,,Operator,35,Your next question comes from Mark Lipacis with Jefferies.,9
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334145.0,Question,Mark Lipacis,,Analysts,36,"A question coming back to the A100. I'm trying to understand how this kind of fits into the evolution of your solution set over time and the evolution of the demand for the applications. Is -- and I guess if I think about it going back, you had a solution, which is largely training based. And then you kind of introduced solutions that were targeted more inferencing. And now you have a solution, it sounds to my understanding that it solves both inferencing and training efficiently. And so I guess I'm wondering is 3 years, 5 years, 10 years down the line, is this part of the kind of general purpose computing or acceleration framework that you had talked about in the past, Jensen, where Ampere is kind of like an Ampere-class product? Or is this -- would you still -- should we still expect to see inferencing-specific solutions in the market and then training-specific solutions and then an Ampere solution for a different class application? If you could provide a framework for thinking about Ampere in those context, I think that would be helpful.",185
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334146.0,Answer,Jen-Hsun Huang,,Executives,37,"Yes. Thanks for the call, Mark. Good Question. I think the -- if you take a step back, currently in our data centers, the current setup in data centers, starting from probably all the way back, 6, 7 years ago, but really accelerating in the last 5 years and then really accelerating in the last couple of years, we learned our way into it. There are 3 classes of workloads, and they kind of came into acceleration over time. The first class of workload that we discovered was -- the major workload was deep learning training. Deep learning training. And the ideal setup for that today prior to Ampere or yesterday prior to Ampere is the V100 SXM with NVLink, 8 GPUs on one board, and that architecture is called scale up. It's like a supercomputer architecture. It's like a -- it's like a weather simulation architecture. You're trying to build the largest possible computing node you can for one operating system called scale up. And the second thing that we learned along the way was then cloud computing started to grow because researchers around the world needed to get access to an accelerated platform for developing their machine learning algorithms. And because they have a different degree of budget, and they want to get into it, a little bit more lightly and have the ability to scale up to larger nodes, the perfect model for that was actually a V100 PCI Express, not SXM, but PCI Express that allows you to offer 1 GPU all the way up to many GPUs. 
And so that versatility, V100 PCI Express, not as scalable in performance as the V100 SXMs, but it was much more flexible for rentals. Cloud renting was really quite ideal. And then we started to get into inference, and we're on our seventh generation of TensorRT, TensorRT 7.0. Along the way, we've been able to accelerate more and more. And today, we largely accelerate every deep learning inference computational graph that's out there. And the ideal GPU for that was something that has the reduced precision, which is called [indiscernible], reduced precision not with electronics that is focused more for inference -- and because inference is a scale-out application, where you have millions of queries, and each one of the queries are quite small versus scale up, where you have 1 training job and that 1 training job is running for a day. 
It could be running for days and sometimes even weeks. And so scale-up application is for 1 user that uses it for a long period of time on a very large machine. Scale out, it's for millions of users, each one of them have a very small query and that query could last hundreds of milliseconds and where ideally, you like to get it done in hundreds of milliseconds. And so notice, I've said 3 different architecture in a data center today. Most data centers today has a storage server, has CPU servers, and it has scale-up acceleration service with Voltas has scaled out servers with GeForce and then it has scale cloud computing, flexible servers based on V100. And so the ability to predict workload is so hard, and therefore, the utilization of these systems will be spiky. And so we created an architecture that allows for 3 things. 
So things -- the 3 characteristics of Ampere are: number one, it is the greatest generational leap in history. I mean I don't remember a generation where we increased throughput for training and inference by 20x. And it's just a gigantic -- for training and for inference, it is a gigantic leap forward. The second, it's the first architecture that is unified. We could use this to the computational -- the computation engine of Ampere accelerates the moment the data comes into the data center. From data processing, it's called [ ETO ]; the engine, which many of you probably know, it's the single most important computational engine in the world today for big data. It used to be Hadoop, but now it's Spark. Spark is used all over the world, 16,000 customers. We finally have the ability to accelerate that. 
And then it's -- Ampere is also good for training, deep learning, machine learning, extra boost as well as deep learning, all the way out to inference. And so we now have a unified acceleration platform for the entire workload. And then the third thing is it's the first GPU ever, the first acceleration platform ever that's elastic. You could reconfigure it. You could configure it for either scale up or you can configure it for scale out. When you configure it for scale up, you're gaining a whole bunch of GPUs together using NVLink, and it creates this 1 gigantic GPU. When you want to scale it out, that same computation node becomes 56 small GPUs. Each one of those 56 partitions, each 1 is more powerful than Volta. 
I mean it's really quite extraordinary. And so Ampere is a breakthrough on all of these fronts for performance for the fact that it unifies the workload, and you can now have 1 acceleration cluster; and then number three, it's elastic. You could use in the cloud, you could use for inference, you could use it for training. And so the versatility of Ampere is the thing that I'm most excited about. And now you could have 1 acceleration cluster that serves all of your needs. That's very helpful.",915
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334147.0,Question and Answer Operator Message,Operator,,Operator,38,Your next question comes from Timothy Arcuri with UBS.,9
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334148.0,Question,Timothy Arcuri,,Analysts,39,"Actually I had 2, I guess, Jensen, first for you. Just on the data center business, things have been very strong recently. Obviously, there's always concerns that customers are pulling in CapEx, but it sounds like you have pretty good visibility into July. But I guess last time, most folks also thought that your kind of attrition really was so low that you would be immune into any digestion, but that wasn't the case. So I guess I'm wondering, if things are different now with A100 and whatnot, but my question is how do you handicap your ability to this time, maybe get through any digestion on the CapEx side? And then I guess, second question, Colette, stock comp had been running like 220 a quarter, and the guidance implies that it goes to like 460 a quarter. So it goes up a lot. Is that all executive retention? And is that sort of the right level as you look into 2021?",162
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334149.0,Answer,Jen-Hsun Huang,,Executives,40,"Colette, did you want to handle that first? And then I'll do the...",13
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334150.0,Answer,Colette Kress,,Executives,41,"Sure. So let me help you out on the overall GAAP adjustments, so the delta between our GAAP OpEx and our non-GAAP OpEx. If you look at it for the full year and what we guided, we probably have about $1.55 billion associated with GAAP level expenses. Keep in mind, there is more in there than just our stock-based compensation. We have also incorporated the accounting that we will do for the overall Mellanox, and a really good portion of those costs are associated with the amortization of intangibles and also in terms of acquisition-related costs and deal fees and onetime items. So our stock-based compensation includes what we need for NVIDIA and also the onboarding of Mellanox. There is some retention with the overall onboarding of Mellanox. But for the most part, it is just working them in to the year for 3 quarters, which is influencing the stock-based compensation.",151
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334151.0,Answer,Jen-Hsun Huang,,Executives,42,"Tim, there are several differences between our condition then and our condition today. So the first -- the first difference is the diversity of workload we now accelerate. Back then, we were early in our inference. We were still early in our inference, and most of the data center acceleration was used for deep learning. And so today, the versatility stands from data processing to deep learning and the number of -- the number of different types of AI models that's being trained for deep learning is growing tremendously from detecting, from training video, from training a model to detecting unsafe video. The natural language understanding the conversational AI to now a gigantic movement towards deep recommender systems. And so the number of different models that are being trained is growing. The size of the models are gigantic. Recommendation systems are gigantic. They're training on models that are hundreds. The data sizes, hundreds of terabytes. Terabytes, hundreds of terabytes. And it would take tens of -- hundreds of servers to hold all of the data that is needed to train these recommender systems. And so the diversity of -- from data analytics to training all the different models to the influence of all different models. We didn't inference recurring elements at a time, which is probably the most important model today. Text language models, speech models are all recurrent, Euronet models. And so those models were early for us at the time. So number one is the diversity of workload. The second is the acceleration of -- to cloud computing. I think that accelerated cloud computing is a movement that is going to be a multiyear if not a decade-long transition. From where we are today, it's only $100 billion industry segment of the IT industry. It's going to be $1 trillion someday, and that movement is just starting. We're also much more diversified out of the clouds. At the time, cloud was largely where our acceleration went for deep learning. And today, hyperscale only represents about half. And so we've diversified significantly out of cloud, not out of cloud, but including vertical industries. And a lot of that has to do with edge AI and inference. And as I mentioned earlier, we're working with Walmart and BMW and USPS, and that's just the tip of the iceberg. And so I think the conditions are a little different. And then what I would say lastly is Ampere. I mean we are -- we've ramped a few weeks. Even though it was quite significant, it was a great ramp. The demand is fantastic. It is the best ramp we've ever had. The demand is the strongest we've ever had in data centers. And we're starting to ramp of a multiyear ramp. And so -- those are some of the differences. I think the conditions are very different.",476
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334152.0,Question and Answer Operator Message,Operator,,Operator,43,Your next question comes from Harlan Sur with JPMorgan.,9
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334153.0,Question,Harlan Sur,,Analysts,44,"Jensen, the team has showed the importance of networking, networking fabric and the Mellanox acquisition, like, for example, when you guys move from Volta DGX-1 to Volta DGX-2, you guys didn't change the GPU chipset. But by adding a custom networking fabric chip and more Mellanox network interface cards, among other things, you guys drove a pretty significant improvement in performance per GPU. But now when we think about scaling out compute acceleration to data center skilled implementation, how does Mellanox' Ethernet switching platforms differ from those provided by other large networking OEMs, some of whom have been your long-term partners? And then how does the Cumulus acquisition fit into the switching and networking strategy as well?",117
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334154.0,Answer,Jen-Hsun Huang,,Executives,45,"Yes. Great. Thanks a lot, Harlan. I appreciate the question. So DGX, you know this is our third-generation DGX and it's really successful. People love it. It's the most advanced AI instrument in the world. If you're a serious AI researcher, this is your instrument. And in the DGX, there are 8 A100s and there are 9 Mellanox NICs, the highest speed NICs they have. And so we have a great appreciation for high-performance networking. High-performance networking and high-performance computing go hand-in-hand. And the reason for that is because the problems we're trying to solve no longer fit in one computer, no matter how big it is. And so it has to be distributed. And when you distribute a computational workload of such intense scale, the communications overhead becomes one of its greatest bottlenecks, which is the reason why Mellanox is so valuable. There's reason why this company is so precious and really a jewel and one of a kind. And so -- and it's not just about the link speed. It's not mostly. 
I mean we just have a deep appreciation for software. It's a combination of architecture and software and electronics design, chip design. And in that combination, Mellanox is just world-class. And that's the reason why they're in 60% of the world's supercomputers. That's why they're in 100% of the AI supercomputers. And their understanding of large-scale distributed computing is second to none. Now in the world of -- and I just talked about scale up. And you're absolutely right. 
Now the question is why scale out? And the reason for that is this. This is the reason why they're doing so well. The movement towards disaggregated microservice applications where containers, microservice containers are distributed all over the data center and orchestrated so that the workload could be distributed across a very large hyperscale data center. That architecture -- and you probably know the 3 most important application in my estimation in the world today, number one, would be TensorFlow and PyTorch; number two would be Spark; and number three would be Kubernetes. And you could rank it however you desire. 
And these 3 applications, in the case of Kubernetes, it's a brand-new type of application where the application is broken up with a small pieces and orchestrated across an entire data center. And because it's broken up into small pieces and orchestrate across the entire data center, the networking between the compute nodes becomes the bottleneck again. And that's the reason why they're doing so well. By increasing the network performance by offloading the communications of the CPUs, you increase the throughput of a data center tremendously. And so it's the reason why they had a record quarter last quarter. It's the reason why they've been growing 27% per year. And their stock was back, their integration into the hyperscale cloud companies, they're low latency, they're incredibly low latency of their link makes them really unique, even whether it's Ethernet or InfiniBand in both cases. 
And so they're -- it's a really fantastic stack. And then lastly, Cumulus, we would like to integrate -- we would like to innovate in this world where the world is moving away from just a CPU as a compute node. The new computing unit, a software developer is writing a piece of software that runs on the entire data center. In the future, going forward, the computing, the fundamental computing unit is an entire data center. It's so incredible. It's just utterly incredible. You write an application, 1 human could write an application, and it would literally activate an entire data center. And in that world, we would like to be able to innovate from end to end, from networking storage, security. Everything has to be secured in the future so that we can reduce the attack surface down to practically nothing. 
And so networking storage, security are all completely offloaded, all incredibly low latency, all incredibly high performance and all the way to compute, all the way through the switch. And then the second thing is we'd like to be able to innovate across the entire stack. You know that NVIDIA is just supremely obsessed about software stacks. And the reason for that is because software creates markets. You can't create new markets like we're talking about, whether it's computational health care or autonomous driving or robotic or conversational AI or recommender systems or edge AI. All of that requires software stacks. It takes software to create markets. And so our obsession about software and creating open platforms for the ecosystem and all of our developer partners, Cumulus plays perfectly into that. They are -- they pioneered the open networking stack. And they pioneered, in a lot of ways, software-defined data centers. And so we're super, super excited about the team. And now we have the ability to innovate in a data center scale world from end to end and then from top to bottom of the entire stack.",830
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334155.0,Question and Answer Operator Message,Operator,,Operator,46,Your next question comes from William Stein with SunTrust.,9
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334156.0,Question,William Stein,,Analysts,47,"Jensen, I'd like to focus on something you said. I think it was in one of your earlier responses, you said something about a very significant part of data centers are now accelerated with GPUs. I'm sort of curious how to interpret that. If we think about sort of the evolution of compute architecture going from almost entirely, let's say, [ REX and REXs ] CPUs to some future day where we have many more accelerators and maybe a much smaller number of CPUs relative to those. Maybe you can talk to us about where we are in terms of that architectural shift and where you think it goes sort of longer term, where we are in the position of that?",121
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334157.0,Answer,Jen-Hsun Huang,,Executives,48,"Yes. I appreciate the question. And this, for computer architecture geeks and people who follow history, you know well that in the entire history of time, there are only 2 computing architectures that has made it so far, which is one of them is x86. The other one's ARM in any reasonable way. And if you get an ARM computer, you get an x86 computer, you can program it. And  in fact, there's no such thing as an accelerated computing platform until we came along. 
And today, we're the only computing -- accelerated computing platform that you could really largely address. We're in every cloud. We're in every computer company. We're in every country. We have every single size, and we accelerate applications from computer graphics to video games to scientific computing to workstations to machine learning to robotics. This journey took 20-some-odd years. Inside our company, it took 20-some-odd years. And we've been focused on accelerated computing since the beginning of our company. And we made a general purpose. We made a general purpose really starting with an endeavor cost Cg, C for graphics, and then it became CUDA. And we've been working on accelerated computing for quite a long time. 
And I think at this point, it's a foregone conclusion that accelerated computing has reached the tipping point and is well beyond it. The number of developers this year that support -- that we supported was almost 2 million developers around the world, and it's growing what appears to be exponentially. And so I think accelerated computing is now well established. NVIDIA-accelerated computing is well established. It's common sense, and people who are designing data centers expect to put accelerated computing in it. The question is how much? How much accelerated computing do you use? And what part of the date in your pipeline do you do it? And the big -- the gigantic breakthrough, of course, we know well now, and NVIDIA is recognized as one of the 3 pillars that ignited the modern AI, the big bang of modern AI. 
And the other 2 pillar, of course, is deep learning algorithm and the abundance of data. And so the 3 -- these 3 ingredients came together and was -- people use NVIDIA accelerated computing largely for training. But over time, we expanded training to have a lot more models. And as I mentioned earlier, the single most important model of machine learning today is the recommender system. It's the most important model because it's the only way that you and I could use the Internet in any reasonable way. It's the only way that you and I could use a shopping website or a video web -- a video app or a music app or book or news or anything. And so it is the engine of the Internet from the consumer's perspective. On the company perspective, it is the engine of commerce. Without the recommender system, there's no way they could possibly make money. 
And so their accuracy in predicting user preferences is core to everything they do. You just go up and down the list of every company. And that engine is gigantic. It is just a gigantic engine. And from the data processing part of it, which is the reason why we went and spent 3 years on Spark and RAPIDS, which made Spark possible and all the work that we did on NVLink and all that stuff was really focused on big data analytics. The second is all of the training of the deep learning models and the inference. So the number of applications, the footprint, the accelerated computing has grown tremendously, and its importance has grown tremendously because of the applications are the most important applications of these companies. And so I think when I mentioned -- when I said that, that acceleration is still growing, it is. But the major workloads, the most important workloads of the world's most important companies are now -- solidly require acceleration. And so I'm looking forward to a really exciting ramp for Ampere for all the reasons that I just mentioned.",687
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334158.0,Question and Answer Operator Message,Operator,,Operator,49,Your next question comes from John Pitzer with Crdit Suisse.,10
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334159.0,Question,John Pitzer,,Analysts,50,"Just 2 quick ones. Colette, I hate to ask something as mundane as OpEx, but just given the full year guide, there's sort of a lot to unpack. And you talked about some of it like the raises. I mean I think you also probably have some COVID plus or minuses in that. I think there's an extra week this year as well. And then, of course, there's Mellanox and how you're thinking about investing in that asset. 
I guess I'm just kind of curious, when we look at the full year guide, is there something structural going on OpEx as you try to take advantage of all these opportunities? Or can we use it as sort of a guidepost to how you're thinking about revenue for the back half of the year as well? How do I understand that? And then, Jensen, just a quick one for you. It kind of makes sense to me that COVID is accelerating activity in sort of HPC and hyperscale and maybe even in certain verticals like health care. But in the other verticals, has the sort of shelter in place kind of hurt engagement? And could we actually come out of COVID with some pent-up demand in those vertical markets?",208
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334160.0,Answer,Colette Kress,,Executives,51,"Okay. Thanks, John, for the question. Let's start from the first perspective on the overall OpEx for the year. We've guided the non-GAAP at approximately $4.1 billion for the year. Yes, that incorporates 3 full quarters of Mellanox, Mellanox and its employees. We have about close to 3,000 Mellanox employees coming on board. You are correct. We have a 53rd week in this quarter -- excuse me, not this quarter, this year. 
And that is -- has been outlined in SEC filings, and you should expect that as well. We pulled forward a little bit our focal by several months in order to take care of our employees. And then lastly though, we are investing in our business. We see some great opportunities. You've seen some good results from our investment, and there's more to do. We are hiring and investing in those businesses. So there's nothing different structurally, but just this onset of Mellanox and are investing together, I think, we'll produce long-term great results.",166
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334161.0,Answer,Jen-Hsun Huang,,Executives,52,"And as usual, John, you know that we're investing into the IT industry's largest opportunities, cloud computing and AI. And then after these 2 opportunities is edge AI. And so we're looking down the fairway with some pretty extraordinary opportunities. But as usual, we're thoughtful about the rate of investment, and we're well-managed. And NVIDIA's leadership team are excellent managers, and you could count on us to continue to do that. Simona, what was John's question? Could you just give me one hint? I haven't...",85
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334162.0,Question,John Pitzer,,Analysts,53,"Just the idea of engagement levels in verticals, just with shelter in place. Has that hampered...",16
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334163.0,Answer,Jen-Hsun Huang,,Executives,54,"Oh yes. Right. Yes, right. Yes, right. A few -- some of the industries have been affected. We already mentioned automotive industry. The automotive industry has been grounded to a halt. Manufacturing hasn't largely stopped. And you saw that in our guidance. We expect automotive to be down 40% quarter-to-quarter. It's not going to remain that way. It's going to come back. And nobody knows what level is going to come back to you and how long, but it's going to come back. And there's no question in my mind that the automotive industry, they're hunkered down right now, but they will absolutely invest in the future of autonomous vehicles. 
They have to, or they'll be extinct. It's not possible not to have autonomous capability in the future of everything that moves. Not so that it could just completely drive without you. That a nice benefit, too. But mostly because of safety and comfort and just a joy of what seems like the car is reading your mind. And of course, you're still responsible for driving it and -- but it just seems to be coasting down the road, reading your mind and helping you. And so I think the future of autonomous vehicles is a certainty. People recognize the incredible economics that the pioneer, Tesla, is enjoying. And the industry is going to go after it. 
The future car companies are going to be software-defined companies and technology companies. And they would love to have an economic that allows them to enjoy the installed base of their fleets. And so they're going to go after it. And so this is -- I'm certain that this is going to come back. And well, I have every confidence is going to come back. And let's see, the energy sectors are -- have been impacted. The retail sector has been impacted. There's -- those aren't large industries for us. The impact in some of the industries is accelerating their focus in robotics. Like, for example, on the one hand, BMW has obviously impacted in manufacturing, which is the reason why they're moving so rapidly towards robotics. They have to figure out a way to get robotics into their factories. So same thing with retail. You're going to see a lot more robotic support in retail, you're going to see a lot more robotic support in warehouses, in logistics. And so during this time, when the market -- when the industry is disrupted and impacted, it allows the market leaders to really lean into investing into the future. And so when they come back, they'll be coming back stronger than ever.",438
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334164.0,Question and Answer Operator Message,Operator,,Operator,55,And your next question comes from Matt Ramsay with Cowen.,10
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334165.0,Question,Matthew Ramsay,,Analysts,56,"Two different topics, Jensen. Well, first of all, congrats on Ampere. It's a heck of a product. The first question...",20
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334166.0,Answer,Jen-Hsun Huang,,Executives,57,"Thank you, Matt. I'm so proud.",6
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334167.0,Question,Matthew Ramsay,,Analysts,58,"The first question is it might have been a little bit hard to talk when the deal was pending about this topic, but now that it's closed, maybe you could talk a little bit about opportunities to innovate on and customize the Mellanox stack and the balance of having an industry standard. And the second one is E3 canceled, Computex moved around. At the same time, there's obviously stay-at-home gaming demand. Just how you think about gaming product, launch logistics? And any comments on there would be really helpful.",89
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334168.0,Answer,Jen-Hsun Huang,,Executives,59,"Yes. Thanks a lot, Matt. I appreciate your questions. I'll go backwards because it's kind of cool. On the one hand, I do miss that we can't engage the developers face to face. It's just so much fun. GTC is doing all their work and the hundreds of papers that are presented, I learned so much each time. And frankly, I really enjoyed the analyst meeting that we have. And so there's all kinds of stuff that I missed about the physical GTC, but here's the amazing thing. 
We had almost -- the GTC kitchen keynote. I did it from my kitchen just right behind me, and the kitchen keynote has been viewed almost 4 million times. And the video is incredible. And so I think our reach is -- could be quite great. And so I'm not too -- we've got an amazing marketing team, and we just -- we've got great people. They're going to find a way to reach our gamers. And whenever we launch something next, you know that gamers are going to be and our customers are going to be -- our end markets are going to be really excited to see it. And so I'm very confident that we're going to do just fine. Matt, what was the question before? I should never do backwards.",221
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334169.0,Question,Matthew Ramsay,,Analysts,60,Just the industry standard versus customization of Mellanox opportunity.,9
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334170.0,Answer,Jen-Hsun Huang,,Executives,61,"I see. Okay. Yes. There's -- we work so closely with Mellanox over the years. And on the day that we announced GTC, you could see the number of products that we have working together. The product synergies are really incredible, and the product synergies include a lot of software development that went in and a lot of architectural development that went in. DGX comes with 9 Mellanox, Matt, as I mentioned. If you look at our data center, we ship -- before we ship DGXs to the customers, we ship it to our own engineers. And the reason for that is because every single product in our company has AI in it. 
From Jarvis to Metropolis to Merlin to DRIVE to Clara to Isaac to -- right? All of our products has AI in it, and we're accelerating frameworks for all of the AI industry. And Ampere comes with a brand-new numerical format called Tensor Float 32. And TF32 is just a fantastic [ medium medical ] format and the performance is incredible. And we had to get it integrated in with the industry standard frameworks. And now Tensor Float comes standard with Tensor Flow -- with TF -- NVIDIA TF32, and PyTorch come standard with TF32. And so we need our own large-scale data center. And so the first customer we ship to was ourselves. And then we started shipping as quickly as we could to all of the customers. You saw that in our data center, in our supercomputer. 
We have 170 -- 170 state-of-the-art, brand-new Mellanox switches. And almost 1,500 -- 200 gigabit per second Mellanox mix. And 15 kilometers of cables, fiber optic cables. And that is one of the most powerful supercomputers in the world today, and it's based on Ampere. And so we have a great deal of work that we did there together. We announced our first edge computer between us and Mellanox in this new card, we call it the EGX A100. It integrates Ampere and it integrates Mellanox' CX-6 Dx, which is designed for 5G telcos and edge computing. It's incredible security and has a single route of trust, and it's virtualized. And so basically, we -- this EGX A100, when you put it into a standard center x86 server, turns that server into a cloud computer in a box. 
The entire capability of a cloud, of a state-of-the-art cloud, which is cloud native, it's secure, it has incredible AI processing, it's now completely hyperconverged inside 1 box. The technology that made EGX A100 is really quite remarkable. And so you could see all the different product synergies that we have in working together. We could have done Spark acceleration without the collaboration with Mellanox. They worked on this piece of networking software called UCX. We worked on [ nickel ] together. It made possible the infrastructure for large-scale distributor computing. I mean just the list goes on and on and on. And so we -- the 2 teams have great chemistry. The culture -- it's a great culture fit. I love working with them. And right out of the chute, you saw all of the great product synergies that are made possible because of the combination.",537
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334171.0,Question and Answer Operator Message,Operator,,Operator,62,That is all the time we have for questions. I'll turn the call back to Jensen Huang for closing remarks.,20
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334172.0,Answer,Jen-Hsun Huang,,Executives,63,"It's coming. Let me just -- thank you. We had a great and busy quarter. With our announcements, we highlighted several initiatives. First, computing is moving to data center scale where computing and networking go hand in hand. The acquisition of Mellanox gives us deep expertise and scale to innovate from end to end. Second, AI is the most powerful technology force of our time. Our Ampere generation offers several breakthroughs. It is the largest ever generational leap 20x in training and inference throughput; the first unified acceleration platform for data analytics, machine learning, deep learning, training and inference; and the first elastic accelerator that can be configured for scale-up applications like training to scale-out applications like inference. 
Ampere is fast, it's universal and it's elastic. It's going to re-architect the modern data center. Third, we are opening large new markets with AI software application framework, such as Clara for health care, DRIVE for autonomous vehicles, Isaac for robotics, Jarvis for conversational AI, Metropolis for edge IoT, AERIAL for 5G and Merlin with the very important recommender systems. And then finally, we have built up multiple engines of accelerated computing growth. RTX computer graphics, artificial intelligence, and data center scale computing from cloud to edge. I look forward to updating you on our progress next quarter. Thanks, everybody.",219
32307.0,"NVIDIA Corporation, Q1 2021 Earnings Call, May 21, 2020",2020-05-21,48.0,Earnings Calls,NVIDIA Corporation,5864.0,2027941.0,79334173.0,Question and Answer Operator Message,Operator,,Operator,64,This concludes today's conference call. You may now disconnect.,10
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710452.0,Presentation Operator Message,Operator,,Operator,0,"Good afternoon. My name is David, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's financial results conference call. [Operator Instructions]
Simona Jankowski, you may begin your conference.",38
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710453.0,Presenter Speech,Simona Stefan Jankowski,,Executives,1,"Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the second quarter of fiscal 2021. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer. I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the third quarter of fiscal 2021. The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. 
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. All our statements are made as of today, August 19, 2020, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. 
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website. 
With that, let me turn the call over to Colette.",254
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710454.0,Presenter Speech,Colette Kress,,Executives,2,"Thanks, Simona. Q2 was another extraordinary quarter. The world continued to battle the COVID-19 pandemic, and most of our employees continued to work from home. But through the team's agility and dedication, we successfully combined Mellanox into NVIDIA while also delivering a very strong quarter. revenue was $3.87 billion, up 50% year-on-year, up 26% sequentially and well ahead of our outlook. 
Starting with gaming. Revenue was $1.65 billion, was up 26% year-on-year and up 24% sequentially, significantly ahead of our expectations. The upside is broad-based across geographic regions, products and channels. Gaming's growth amid the pandemic highlights the emergence of a leading form of entertainment worldwide. For example, the number of daily gamers on Steam, a leading PC game online distributor is up 25% from pre-pandemic levels. And NPD reported that U.S. consumer spending on video games grew 30% in the second calendar quarter to a record $11 billion. 
NVIDIA's PCs and laptops are ideal for the millions of people who are now working, learning and gaming at home. At the outset of the pandemic, many retail outlets were closed, and demand shifted to online channels. As the quarter progressed and the stores reopened, retail demand picked up, iCafes largely reopened and online sales continued to thrive. Gaming laptop demand is very strong as students and professionals turn to GeForce-based systems to improve how they work, learn and game from home. We ramped over 100 new models with our OEM partners, focused on both premium and mainstream price points. 
In the premium laptop segment, we delivered unparalleled performance with the GeForce RTX 2080 and the 2070 SUPER GPUs InfiniBand form factors. We also brought ray tracing to gaming laptops for the first time at price points as low as $999 with the GeForce RTX 2060. In the mainstream segment, we brought the GeForce GTX to laptop price points as low as $699. 
Momentum continues for our Turing architecture, which enables stunning new visual effects in games and is driving powerful upgrade cycle among gamers. Its RTX technology adds ray tracing and AI to programmable shading and has quickly redefined the new standard for computer graphics. DLSS used the AI capabilities of Turing to boost frame rates by almost 2x while generating crisp image quality. RTX support in blockbuster games continues to grow, including megahit Death Stranding, the high anticipated Cyberpunk 2077 and the upcoming release of Watch Dogs. These games join Minecraft and other major titles that support NVIDIA RTX ray tracing and DLSS. 
We're in the midst of a 21-day countdown campaign, promoting a GeForce special event on September 1, with each day highlighting a year in the history of GeForce. We don't want to spoil the surprise, but we encourage you to tune in. We are very pleased with the traction of our GeForce NOW cloud gaming service, now in its second quarter of commercially availability. GFN offers the richest content to any game streaming service through partnerships with leading digital game stores, including Valve Steam, Epic Games and Ubisoft Uplay. GeForce NOW enables users with underpowered PC, Macs or Android devices to access powerful GPUs to play their libraries of PC games in the cloud, expanding the universe of gamers that we can reach with GeForce. 
Just yesterday, we announced that GFN is now supported on Chromebooks, further expanding our reach in to tens of millions of users. In addition to NVIDIA's own service, GFN is available or coming soon to a number of telecom partners around the world, including SoftBank and KDDI DION in Japan, Rostelecom and Beeline in Russia, LG U+ in South Korea and Taiwan Mobile. 
Moving to Pro Viz. In Q2 was $203 million in revenue, down 30% year-on-year and down 34% sequentially, with declines in both mobile and desktop workstations. Sales were hurt by lower enterprise demand amid the closure of many offices around the world. Industries negatively impact during the quarter include automotive, architectural, engineering and construction, manufacturing, media and entertainment and oil and gas. Initiatives by enterprises to enable remote workers drove demand for virtual and cloud-based graphic solutions. Accordingly, our Q2 vGPU bookings accelerated, increasing 60% year-on-year. 
Despite near-term challenges, we are winning new business in areas such as health care, including Siemens, Philips and General Electric, and the public sector. We continue to expand our market opportunity with over 50 leading design and creative applications that are NVIDIA RTX-enabled, including the latest release from Foundry, Chaos Group and Maxon. These applications provide faster ray tracing and accelerated performance, improving creators design workflows. The pandemic will have a lasting impact on how we work. Our revenue mix going forward will likely reflect this evolution in enterprise workforce trends with a greater focus on technologies, such as NVIDIA laptops and virtual workstations, that enable remote work and virtual collaboration. 
Moving to automotive. Automotive revenue was $111 million, down 47% year-on-year and down 28% sequentially. This was slightly better than our outlook of a 40% sequential decline as the impact of the pandemic was less pronounced than expected, with auto production volumes starting to recover after bottoming in April. Some of the decline is also due to the roll-off of legacy infotainment revenue, which remained a headwind in future quarters. 
In June, we announced a landmark partnership with Mercedes-Benz which, starting in 2024, will launch software-defined intelligent vehicles across an entire fleet in using end-to-end NVIDIA technology. Mercedes will utilize NVIDIA's full technology stack, including the DRIVE AGX computer, DRIVE AV autonomous driving software and NVIDIA's AI infrastructure, spanning from the core to the cloud. Centralizing and unifying computing in the car will make it easier to integrate and upgrade advanced software features as they are developed. With over-the-air updates, vehicles can receive the latest autonomous driving and intelligent cockpit features, increasing value and extending majority of ownership with each software upgrade. This is a transformative announcement for the automotive industry, making the turning point of traditional vehicles becoming high-performance, updatable data centers on wheels. It's also a transformative announcement for NVIDIA's to evolving business model as the software content of our platforms grows, positioning us to build a recurring revenue stream. 
Moving to data center. Data center is diverse, consist of cloud service providers, public cloud providers, supercomputing centers, enterprises, telecom and industrial edge. Q2 revenue was a record $1.75 billion, up 167% year-on-year and up 54% sequentially. In Q2, we incorporated a full quarter of contribution from the Mellanox acquisition, which closed on April 27, the first day of our quarter. Non-ops contributed approximately 14% of company revenue and just over 30% of data center revenue. Both compute and networking within data center set a record with accelerating year-on-year growth. 
The biggest news in data center this quarter was the launch of our Ampere architecture. We are very proud of the team's execution in launching and ramping this technological marvel, especially amid the pandemic. The A100 is the largest chip ever made with 54 billion transistors. It runs our full software stack for accelerating the most compute-intensive workloads. Our software leases include CUDA 11, the new versions of over 50 CUDA-X libraries and a new application frameworks for major AI workloads, such as Jarvis for conversational AI and Merlin for deep recommender systems. The A100 delivers NVIDIA's greatest generational leap ever, boosting AI performance by 20x over its predecessor. It is also our first universal accelerator, unifying AI training and inference and powering workloads, such as data analytics, scientific computing, genomics, edge video analytics, 5G services and graphics. 
The first Ampere GPU, A100, has been widely adopted by all major server vendors and cloud service providers. Google Cloud Platform was the first cloud customer to bring it to market, making it the fastest GPU to come to the cloud in our history. And just this morning, Microsoft Azure announced the availability of massively scalable AI clusters, which are based on the A100, and interconnected with 200 gigabyte per second Mellanox InfiniBand networking. A100 is also getting incorporated into offerings from AWS, Alibaba Cloud, Baidu Cloud and Tencent Cloud. And we announced that the A100 is going to market with more than 50 servers from leading vendors around the world, including Cisco, Dell, Hewlett Packard Enterprise and Lenovo. Adoption of the A100 into leading server makers offerings is faster than any prior launch, with 30 systems expected this summer and over 20 more by the end of the year. 
The A100 is already winning industry recognition. In the latest A100 training benchmark, MLPerf 0.7, NVIDIA set 16 records, sweeping all categories for commercially available solutions in both per chip and outscale performance based on the A100. MLPerf offers the industry's first and only objective AI benchmark. Since the benchmark was introduced 2 years ago, NVIDIA has consistently delivered leading results and record performance for both training and inference. NVIDIA also topped the chart in the latest top 500 list of the fastest supercomputers. The ranking, released in June, showed that 8 of the world's top 10 supercomputers use NVIDIA GPUs, NVIDIA networking or both. They include the most powerful systems in the U.S. and Europe. NVIDIA, now combined with Mellanox, powers 2/3 of the top 500 systems on the list compared with just less than a half for the 2 companies in total 2 years ago. 
In energy efficiencies, systems using NVIDIA GPUs are pulling away from the pack. On average, they are nearly 2.8x more powerful and efficient than systems without NVIDIA GPUs, measured by gigaflops per watt. The incredible performance and efficiency of the A100 GPU is best amplified by NVIDIA's own new Selene supercomputer, which debuted as #7 on the top 500 list and is the only top 100 systems to cross the 20 gigaflops per watt barrier. Our engineers were able to assemble Selene in less than 4 weeks using NVIDIA's open modular DGX SuperPOD reference architecture instead of the typical build time of months or even years. This is the system that we will use to win the MLPerf benchmarks, and it is a reference design. It's available for our customers to quickly build a world-class supercomputer. 
We also brought GPU acceleration to data analytics, one of the largest and fastest-growing enterprise workload. We enabled an acceleration of the entire data analytics workload pipeline for the first time with NVIDIA's GPUs and software stack in the latest version of Apache Spark released in June. Spark is the world's leading data analytics platform used by more than 500,000 data scientists and 16,000 enterprises worldwide. 
And we have 2 major milestones to share. We have now shipped a cumulative total of 1 billion CUDA GPUs, and the total number of developers in the NVIDIA ecosystem just reached 2 million. It took over a decade to reach the first million and less than 2 years to reach the second million. Mellanox has fantastic results across the board in its first quarter as part of NVIDIA. Mellanox revenue growth accelerated with strength across Ethernet and InfiniBand products. Our Ethernet shipments reached a new record. Major hyperscale build drove the upside in the quarter as growth in cloud computing and AI is fueling increased demand for high-performance networking. Mellanox networking was a critical part of several of our major new product introductions this quarter. These include the DGX AI system, the DGX SuperPOD clusters for our Selene supercomputer and the EGX Edge AI platform. We also launched the Mellanox ConnectX-6 Ethernet NIC, the 11th generation product of the ConnectX family, and it's designed to meet the needs of modern cloud and hyperscale data centers, where 25, 50 and 100 gigabyte per second is becoming the standard. 
We expanded our switch networking capabilities with the addition of Cumulus Networks, a privately held network software company that we purchased in June. Cumulus augments our Mellanox acquisition in building out open modern data center. The combination of NVIDIA accelerated computing, Mellanox networking and Cumulus software enables data centers that are accelerated, disaggregated and software-defined to meet the exponential growth in AI, cloud and high-performance computing. 
Moving to the rest of the P&L. Q2 GAAP gross margin was 58.8% and non-GAAP gross margin was 66%. GAAP gross margin declined year-on-year and sequentially due to costs associated with the Mellanox acquisition. Non-GAAP gross margins increased by almost 6 points year-on-year, reflecting a shift in product mix with higher data center sales and lower automotive sales. Q2 GAAP operating expenses were $1.62 billion, and non-GAAP operating expenses were $1.04 billion, up 67% and 38% from a year ago, respectively. Q2 GAAP EPS was $0.99, up 10% from a year earlier. Non-GAAP EPS was $2.18, up 76% from a year ago. Q2 cash flow from operations was $1.57 billion. 
With that, let me turn to the outlook for the third quarter of fiscal 2021. We expect revenue to be $4.4 billion, plus or minus 2%. With that, we expect gaming to be up just over 25% sequentially with data center to be up in the low to mid-single digits sequentially. We expect both pro viz and the auto to be at similar levels out in Q2. GAAP and non-GAAP gross margins are expected to be 62.5% and 65.5%, respectively, plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $1.54 billion and $1.09 billion, respectively. Full year GAAP and non-GAAP OpEx is tracking in line with our outlook of $5.7 billion and $4.1 billion, respectively. GAAP and non-GAAP OI&E are both expected to be expense of approximately $55 million. GAAP and non-GAAP tax rates are both expected to be 8%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $225 million to $250 million. Further financial details are included in the CFO commentary and other information available on our IR website. 
In closing, let me highlight upcoming events for the financial community. We will be at the BMO Virtual Technology Summit on August 25, Citi's 2020 Global Technology Conference on September 9, Deutsche Bank's Technology Conference on September 14 and the Evercore's Virtual Memo Forum, The Future of Mobility, on September 21. We will also host a financial analyst Q&A with Jensen on October 5 as part of our next virtual GTC. Our earnings call to discuss our third quarter's results is scheduled for Wednesday, November 18. 
We will now open the call for questions. Operator, would you please poll for questions? Thank you.",2398
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710455.0,Question and Answer Operator Message,Operator,,Operator,3,[Operator Instructions] Your first question comes from the line of Vivek Arya with Bank of America.,16
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710456.0,Question,Vivek Arya,,Analysts,4,"Congratulations on the strong growth and execution. Jensen, I'm wondering how much of the strength that you're seeing in gaming and data center is maybe more temporary because COVID or some customer pull-ins in the data center or so forth? And how much of it is more structural and more secular that can continue even once we get into, hopefully, sooner rather than later, into a more normalized period for the industry?",72
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710457.0,Answer,Jen-Hsun Huang,,Executives,5,"Yes. Vivek, thank you. So first of all, we didn't see pull-ins, and we're in the beginning of our brand-new product cycle with Ampere. And so the vast majority of the data center growth came from that. The gaming industry, they -- with all that's happening around the world, and it's really unfortunate, but it's made gaming the largest entertainment medium in the world. More than ever, people are spending time digitally, spending on time -- spending their time in video games. The thing that people haven't realized about video games is that it's not just the game itself anymore. The variety of different ways that you can play, whether you can hang out with your friends in Fortnite, go to a concert in Fortnite, building virtual worlds in Minecraft, you're spending time with your friends, you're using it to create -- to realize your imaginations. 
People are using it for broadcast, for sharing ideas and techniques with other people, and so -- and then of course, it's just an incredibly fun way to spend time even by consumption of the video -- of a video game. And so there's just so much that you could do with video games now. And I think that this way of enjoying entertainment digitally has been accelerated as a result of the pandemic, but I don't think it's going to return. Video game adoption has been going up over time and pretty steadily. PC is now the single largest entertainment platform -- is the largest gaming platform. And GeForce is now the largest gaming platform in the world. And as I mentioned, it's not just about gaming. There's just so many different ways that you could enjoy games. 
With data center, the thing that -- the structural change that's happening in data center are a couple of different dynamics that are happening at the same time. The first dynamic, of course, is the movement to the cloud. The way that a cloud data center is built and the way that an enterprise data center or a cluster is built is fundamentally different. And it's really, really beneficial to have the ability to accelerate applications that cloud service providers would like to offer, which is basically everything. And we know that one of the most important applications of today is artificial intelligence. It's a type of software that really wants acceleration, and NVIDIA's GPU acceleration is the perfect medium, perfect platform for it.
And then the last reason about the data center is the architectural change from hosting applications to hosting services that's driving this new type of architecture called disaggregation versus hyper converged. And the original name of hyperscalers is a large data center of a whole bunch of hyperconverged computers. But the computers of today are really disaggregated. A single application service could be running on multiple servers at the same time, which generates a ton of east-west traffic, and a lot of it is artificial intelligence neuro network models. 
And so because of this type of architecture, 2 components, 2 types of technologies are really important to the future of cloud. One of them, as I mentioned, was -- is acceleration, and our GPU is ideal for it. And then the other one is high-speed networking. And the reason for that is because the server is now disaggregated, the application is fractionalized and broken up into a bunch of small pieces that are running across the data center. And whenever an application needs to send parts of the answer to another server for the microservice to run, that transmission is called east-west traffic, and the most important thing you could possibly do for yourself is to buy really high-speed, low-latency networking. And that's what Mellanox is fantastic at. 
And so we find ourselves really in this perfect condition where the future is going to be more virtual, more digital, and that's one -- that's the reason why GeForce is so successful. And then we find ourselves in a world where the future is going to be more autonomous and more AI-driven, and that's the benefit of our GPUs. 
And then lastly, cloud microservice transactions really benefit high-speed networking, and that's where Mellanox comes in. And so I think that this is -- the dynamics that I'm describing are permanent, and it's just been accelerated to the present because of everything that's happening to us. But this is the future, and it's not -- there's no going back, and we just found everything accelerated.",752
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710458.0,Question and Answer Operator Message,Operator,,Operator,6,Your next question comes from the line of Timothy Arcuri with UBS.,12
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710459.0,Question,Timothy Arcuri,,Analysts,7,"Jensen, I guess I had a question on both architecture and also manufacturing. And I think on the manufacturing side, you've been radical now for some time. And when you've been asked in the past about moving to more of a tiled or chiplet approach, you sort of made light of that. But the CPU guys are clearly taking that approach. So I guess the question is, why do you think you won't have to make a similar move? And then on the side of architecture, the theme of Hot Chips this week was really how compute demand is far outstripping computing power? And then we see this talk about you and ARM. So I guess can you talk about whether GPU is the future and maybe the broader opportunity to integrate CPU and GPU?",135
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710460.0,Answer,Jen-Hsun Huang,,Executives,8,"Yes. We push architecture really hard. And the way we push architecture is we start from the system, but we believe that the future computer company is a data center-scale company. The computing unit is no longer a microprocessor or even a server or even a cluster. The computing unit is an entire data center now. And as I was explaining to Vivek just now that a microservice that we're enjoying hundreds of billions of transactions a day, those are broken up into a whole bunch of microservices that are running across the entire data center. 
And so the data center is running -- the entire data center is running an application. I mean that's pretty remarkable thing, and that's happened in the last several years. We were ahead of this trend, and we recognized that as a computing company, we have to be a data center-scale company, and we architect from that starting. If you look at our architecture, we were the first in the world to create the concept of an NVLink with 8 processors being fully synchronized across a computing node, and we created the DGX. 
We recognize the importance of high-speed networking and low-latency networking, and that's why we bought Mellanox. And the amount of software that we invented along the way to make it possible for low-latency communications, whether it's GPUDirect or recently the invention of GPUDirect Storage, all of that technology was inspired by the idea that you have to think about the data center all-in-one holistic way. 
And then in the last -- in this current generation with Ampere, we invented the world's first multi-instance GPU. We invented the world's first multi-instance GPU, which means that our Ampere GPU could simultaneously be 1 GPU or, with NVlink, 8 GPUs combined, working together, so you could think of them as being tiled. So those 8 GPUs are working harmoniously together. Or each one of the GPUs could fractionalize itself, if you don't need that much GPU working on your workload, fractionalize into a multi-GPU instance, we call the MIG, a little tiny instance. And each one of those tiny instances are more powerful and more performant than our entire Volta GPU lap time. And so whether you like to fractionalize the GPU, which happens oftentimes; create a larger GPU using NVLink; or create an even larger GPU, the size of DGX POD, connected together with high-speed, low-latency networking with Mellanox, we could architect it any way you'd like. 
You made a comment about -- you asked a question about ARM. We've been a long-term partner of ARM, and we use ARM in a whole bunch of applications. And whether it's autonomous driving or a robotics application, the Nintendo Switch, console business that we're in. And then recently, we brought CUDA to ARM and to bring accelerated computing to ARM. And so we worked with the ARM team very closely. They're really great guys. And one of the specials about the ARM architecture that you know very well is that it's incredibly energy-efficient. And because it's energy-efficient, it has the headroom to scale into very high-performance levels over time. And so anyways, we love working with the ARM guys.",534
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710461.0,Question and Answer Operator Message,Operator,,Operator,9,Your next question comes from the line of Aaron Rakers with Wells Fargo.,13
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710462.0,Question,Aaron Rakers,,Analysts,10,"Congratulations on the quarter. Just building on some prior questions. The first one, I was just curious if you could help us appreciate kind of the installed base of the gaming GPU business relative to where we're at the Turing upgrade cycle. What do we see still on prior generations, be it Pascal or before? And then secondly, I was wondering, Colette, could you just give me a kind of updated commentary or views on visibility in the data center business? How has that changed over the last 3 months? What does that look like as you look through the back half of the calendar year?",106
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710463.0,Answer,Jen-Hsun Huang,,Executives,11,"Yes. Thanks a lot, Aaron. We are -- we're still in the ramping of the RTX generation. Turing, Turing the current generation that we're in, is the world's first ray tracing GPU. And it fuses -- the RTX technology fuses 3 fundamental technologies: the programmable shader that we introduced a long time ago that revolutionized computer graphics; and we added 2 new technologies. One technology is a ray tracing acceleration core that makes the tracing of rays and looking for intersections between the ray and the scene -- objects in the scene super, super fast. And that -- it's a complicated problem. It's a super-complicated problem. We want it to be running concurrently to shading so that the ray traversal and the shading of the pixels could be done independently and concurrently. 
The second thing is we invented this technology to bring AI, artificial intelligence, using this new type of algorithm called deep learning to computer graphics. And one example of its capability is the algorithm we introduced called DLSS, Deep Learning Super Sampling, which allows us to essentially synthesize by learning from previous examples, essentially learning from previous examples of images and remembering it, remembering what beautiful images look like so that when you take a low-resolution image, and you run it through the deep neural network, it synthesizes a high-resolution image that's really, really beautiful. And people have commented that it's even more beautiful than native rendered images at the native resolution. And the benefit is not only is it beautiful, it's also super fast. We essentially nearly doubled the performance of RTX as a result of doing that. So you can have the benefit of ray tracing as well as very high resolution and very high speed. And so that's called RTX. 
And Turing is probably not even close, not even 1/3 of the total installed base of all of our GeForce GPUS, which is, as you know, the single-largest installed base of gaming platforms in the world. And so we support this large installed base, and we're in the process of bringing them to the future with RTX. And now with the new console generation coming, every single game developer on the planet is going to be doing ray tracing, and they're going to be creating much, much richer content. And because of multi-platform, cross-platform play and because of the size of the gaming platform, PC gaming platform, it's really important that these game developers bring the latest generation content to PCs, which is great for us.",421
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710464.0,Question,Aaron Rakers,,Analysts,12,And then on the data center visibility?,7
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710465.0,Answer,Colette Kress,,Executives,13,"Yes. Let me see if I can answer this one for you. Yes, we have been talking about our visibility of data center. And as you've seen in our Q2 results, you can see that our overall adoption of the NVIDIA computing portfolio has accelerated quite nicely. But keep in mind, we're still really early in the product cycle. A100 is ramping. It's ramping very strong into our existing installed bases but also into new markets. Right now, A100 probably represents less than 1/4 of our data center revenues. So we still have a lot to grow. 
We have good visibility looking into Q3 with our hyperscales. We have a little bit more of a mixed outlook in terms of our vertical industries, given a lot of the uncertainty in the market and in terms of the overall economy. On-premises are challenged because of the overall COVID. But remember, industries are quickly and continuing to adopt and move to the overall cloud. But overall, we do expect a very strong Q3.",171
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710466.0,Question and Answer Operator Message,Operator,,Operator,14,Your next question comes from the line of C.J. Muse with Evercore ISI.,14
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710467.0,Question,Christopher Muse,,Analysts,15,"I guess 2 questions. If I look at your outstanding inventory purchase obligations, grew, I think, 17% sequentially. Is that as you prepare for the September 1 launch? And can you kind of comment on gaming visibility into the back half of the year? And then the second question, Jensen, I know you're very focused on platforms and driving recurring revenues. Would love to hear if there's any particular platforms over the last 3 months where you've made real headway or get you excited, whether Jarvis, Merlin, Spark or whatever.",90
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710468.0,Answer,Jen-Hsun Huang,,Executives,16,"Yes. Thanks so much, C.J. We're expecting a really strong second half for gaming. I think this may very well be one of the best gaming seasons ever. And the reason for that is because PC gaming has become such a large format. The combination of amazing games like Fortnite and Minecraft and because of the way people game now, their gaming and their e-sporting, even F1 is an e-sport now. They're hanging out with friends. They're using it to create other content. They're using game captures, create art. They're sharing it with the community. It's a broadcast medium. The number of different ways you could game has just really, really exploded. And it works on PCs because all the things that I described require cameras or keyboards or streaming systems or -- and -- but it requires an open system that is multitasking. And so the PC has just become such a large platform for gaming. 
And the second thing is that RTX, it's a home run. We really raised the bar with computer graphics, and the games are so beautiful, and it's really, really the next level. It's not been this amazing since we introduced programmable shaders about 15 years ago. And so for the last 15 years, we've been making programmable shaders better and better and better, and it has been getting better. But there's never been a giant leap like this, and RTX brought both artificial intelligence as well as ray tracing to PC gaming. 
And then the third factor is the console launch. There's -- people are really -- the game developers are really gearing up for a big leap. And because of the gaming -- because how vibrant the gaming market is right now and how many people around the world is depending on gaming at home. I think it's going to be the most amazing season ever. We're already seeing amazing numbers from our console partner, Nintendo. Switch has -- about to sell more than Super Nintendo, more than all the Famicom, which was one of the best gaming consoles of all time. I mean they're underway to make Switch the most successful gaming platform of all time. And so I'm super excited for them. And so I think it's going to be quite a huge second half of the year.",388
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710469.0,Question and Answer Operator Message,Operator,,Operator,17,Your next question comes from the line of Toshiya Hari of Goldman Sachs.,13
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710470.0,Answer,Jen-Hsun Huang,,Executives,18,"Colette, I felt like I didn't -- I missed C.J.'s second question. Can we jump on and answer it?",19
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710471.0,Answer,Colette Kress,,Executives,19,I think the question was regarding our inventory purchases on that piece. Is that the part that you're referring to?,20
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710472.0,Answer,Jen-Hsun Huang,,Executives,20,Yes. That's the one. Yes.,5
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710473.0,Answer,Colette Kress,,Executives,21,"Yes. Keep in mind, C.J., that when you think about the complexity of the products that we are building, we have extremely long lead times, both in terms of what we produce for the data center, our full systems that we need to do as well as what you are seeing now between the sequential growth between Q2 and Q3 for overall gaming. So all of that is in preparation for the second half. Nothing unusual about it other than, yes, we've got to hit those revenue numbers that are in our Q3 guidance.",94
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710474.0,Question and Answer Operator Message,Operator,,Operator,22,Your next question comes from the line of Toshiya Hari with Goldman and Sachs.,14
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710475.0,Question,Toshiya Hari,,Analysts,23,"I had one for Jensen and another one for Colette. Jensen, just following up on the data center business. As you probably know, quite a few of your peers have been talking about potential digestion of capacity on the part of your hyperscale customers over the next, call it, 6 to 12 months. Curious, is that something that you think about, worry about in your data center business? Or do you have enough idiosyncratic growth drivers like the A100 ramp? And I guess the breadth that you've built within your data center business across compute and networking, are those enough for you to buck the trend within data center over the next 6 to 12 months? 
And then the second one for Colette, just on gross margins. You're guiding October quarter gross margins down 50 basis points sequentially. Based on the color that you provided for the individual segments, it looks like mix remains pretty positive. So just curious what's driving the marginal decline in gross margins in the October quarter?",171
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710476.0,Answer,Jen-Hsun Huang,,Executives,24,"Yes. Thank you. So thanks for the question. The -- our data center trend is really tied to a few factors. One is the proliferation of using deep learning and artificial intelligence and all the services that are in -- by the cloud service providers. And I think it's fair to say that over the last several years, the number of breakthroughs in artificial intelligence has been really terrific. And we're seeing anywhere from 10x, 10x more computational requirement each year to more than that. And so in the last 3 years, we've seen somewhere between 1,000 to 3,000x increase in the size of models, the computational requirement necessary to create these AI models and to deploy these AI models. 
And so the #1 trend that we're probably indexed to is the breakthroughs of AI and the usefulness of AI and how people are using it. And one of the -- and I remember C.J.'s question now, and I'll answer this along with that. One of the things that we look for and you should look for is how -- what kind of breakthroughs are based on deep learning and based on AI that these services all demand.
And there are 3 big ones, just gigantic one. Of course, one of them is natural language understanding, the ability to take a very complicated text and use deep learning to create essentially a dimension reduction, it's called deep embedding, dimension reduction on that body of text so that you could use that vector as a way to teach a recommender system, which is the second major breakthrough, the recommender system, how to predict and make a recommendation to somebody. Recommendation on ads and videos, and there are trillions of videos on the web. You need ways to recommend them, both the news and just the amount of information that is going to -- that is in true dynamic form require these recommenders to be instantaneous.
And so the first one is natural language understanding. The second one is the recommender system, gigantic breakthroughs in the last several years. And the third is conversational AI. I mean we're going to have conversational engines that are just super clever, and they can predict what you're about to ask. They're going to predict the right answer for you, make recommendations to you based on the 3 pillars that I just described. 
And I haven't even started talking about robotics, the breakthroughs that are happening there with all the factories that need to automate and breakthroughs that we're seeing in self-driving cars, the models there are really improving fast. And so the answer to you, Toshiya, and C.J. are kind of similar, that on the first one, we're indexed to AI. The second, we're indexed to breakthroughs of AI. So that it can continue to consume more and more capability and more technology. 
And then the third thing that we're indexed to is the movement of workloads to the cloud. It is now possible to do rendering in the cloud, remote graphics workstations in the cloud. And NVIDIA virtual workstations is in every single cloud. You could do big data analytics in the cloud. And these applications, I've just given you a few applications where you can do scientific computing in the cloud. These applications all have fundamentally different computing architectures. 
NVIDIA is the only accelerated architecture that allows you to do microservices for conversational AI and other types of AI applications to scale up applications like high-performance computing, training, big data analytics to virtualize applications like workstations. Our platform is universal, and these 3 facets that I just described are supremely complex, virtualized, microservices-based and scale-up-based. And so these -- bare metal scale-up. And these are complicated, and it's one of the reasons why we bought Mellanox because they're at the core and at the intersection of all of that. The storage, the networking, the security, the virtualization, they're at the intersection of all of that. And I just described 3 dynamics that are very, very powerful and are at the early stages yet. And so those are the things that we're really indexed to. 
And then lastly, when somebody adopts -- when we introduce a new platform like Ampere, we're in the beginning of a multiyear product cycle, Ampere is such a gigantic breakthrough. It's the first universal GPU we ever created. It is both able to scale up as well as scale out, scale up as in multi GPUs, scale out is fractionalization, multi-instance GPUs. And it's -- it reduced -- it saves money, tremendous amount of money for people who use it. It speeds up their application. It reduces their TCO. Their TCO value just goes through the roof. And so we're in the beginning of this multiyear cycle and the enthusiasm has been fantastic. This is the fastest ramp we've ever had. And so we're going to keep on racing through the second half.",824
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710477.0,Answer,Colette Kress,,Executives,25,"Okay. And Toshiya, you asked a question regarding our guidance going forward regarding gross margin. And within our Q3 guidance, we have just a small decline in our gross margin from Q2. Most of that is really associated with mix but also a little bit in terms of the ramping of our new Ampere architecture products that we have. So keep in mind, our data center will likely be a lower percentage of total revenue, given the strong overall gaming growth that we expect between Q2 and Q3. Within that gaming growth, keep in mind, consoles are also included, which will continue to be below our company totals average gross margin, and that is expected to be up strongly quarter-over-quarter for our overall console shipments. We're going to be ramping those new architectures over time when we have the ability to expand our gross margin as Ampere GPUs mature, too.",150
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710478.0,Question and Answer Operator Message,Operator,,Operator,26,Your next question comes from the line of Stacy Rasgon with Bernstein Research.,13
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710479.0,Question,Stacy Rasgon,,Analysts,27,"I wanted to dig into data center a little bit. This is a question for Colette. So in the quarter, ex Mellanox, data center was up, core data center, maybe 6%, 7%. The guide looks to be roughly similar to that into Q3. Can you talk to us a little bit about what's driving the trajectory? Are you more demand or more supply limited at this point? What does your supply situation look like? And what are the lead times especially on the A100 products for data center look like at this point? Like if you have more capacity available, do you think you'd have like a stronger trajectory than you have right now?",114
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710480.0,Answer,Colette Kress,,Executives,28,"Yes. Stacy, so thanks for the question. Let me first start on our Q3 outlook and what we're seeing. And when we think about our demand and our supply, we're very comfortable with the supply that we have. Keep in mind, our products are quite complex, and a lot of our time is spent in terms of procuring every aspect of that supply over multiple quarters previously. So that's how we work. But we are very confident with the overall supply that we have across the board in data center. Keep in mind that it's not just A100. We are continuing to sell V100 or T4. And we're also bringing new versions of the A100 coming to overall market. So I hope that helps you understand our statements on where are we at in terms of the Q3 guidance. We'll see if Jensen wants to add a little bit more to that.",152
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710481.0,Answer,Jen-Hsun Huang,,Executives,29,"Well, when we're ramping, we sure love to have more and sooner. And -- but this is our plan, and we're executing to the plan. It is a very complicated product, as Colette mentioned. It is the most complicated.",39
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710482.0,Question,Stacy Rasgon,,Analysts,30,"Got it. Got it. And just a quick follow-up. Within the data center guidance, how do you think about like the core data center sequential growth versus Mellanox?",28
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710483.0,Answer,Colette Kress,,Executives,31,"Yes. So in terms of moving from Q2 to Q3, we believe that most of the actual growth that we will receive in that single -- low single-digit to mid-single-digit growth will likely stem from NVIDIA compute, will be the largest driver of that.",44
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710484.0,Question and Answer Operator Message,Operator,,Operator,32,Your next question comes from the line of Joseph Moore with Morgan Stanley.,13
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710485.0,Question,Joseph Moore,,Analysts,33,"I wonder if I could ask a longer-term question about the -- how you guys see the importance of process technology. There's been a lot of discussion around that in the CPU domain. But you guys haven't really felt the need to be first on 7 nanometer, and you've done very well. Just how important do you think it is to be early in the new process node? And how does that factor into the cycle of innovation at NVIDIA?",81
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710486.0,Answer,Jen-Hsun Huang,,Executives,34,"Yes. First of all, thanks, Joe. The process technology is a lot more complex than a number. I think people have simplified it down to almost a ridiculous level, right? And so process technology, we have a really awesome process engineering team, world-class. Everybody will recognize that it's absolutely world-class. And we work with the foundries, we work with TSMC really closely, to make sure that we engineer transistors that are ideal for us and we engineer metallization systems that's ideal for us. It's a complicated thing, and we do it at high part. 
Then the second part of it is where architecture, where the process technology and the rest of the design process, the architecture of the chip, and the final analysis, what NVIDIA paid for, is architecture, not procurement of transistors. We're paid for architecture. And there's a vast difference between our architecture and the second best architecture and the rest of the architectures. The difference is incredible. We are easily twice the energy efficiency all the time, irrespective of the number of the -- in the transistor side. And so it must be more complicated than that. And so we put a lot of energy into that, and then the last thing I would say is that going forward, it's really about data center-scale computing. Going forward, you optimize at the data center scale. And the reason why I know this for a fact is because if you're a software engineer, you would be sitting at home right now, and you will write a piece of software that runs on the entire data center in the cloud. You have no idea what's underneath it, nor do you care. And so what you really want is to make sure that, that data center is as high throughput as possible. There are a lot of code in there. 
And so what NVIDIA has decided to do over the years is to take our game to a new level. Of course, we start with building the world's best processors, and we use the world's best foundries, and we partnered them very closely to engineer the best process for us. We partner with the best packaging companies to create the world's best packaging. We're the world's first user of cobots. And whether it's -- I think we're -- I'm pretty sure we're still the highest volume by far of 2.5D and 3D packaging. 
And so we start from a great chip. We start from a great chip, but we don't end there. That's just the beginning for us. Now we take this thing all the way through systems, the system software, algorithms, networking, all the way up to the entire data center. And the difference is absolutely shocking. We built our data center, Selene, and it took us 4 weeks. We put up Selene in 4 weeks' time. It is the seventh fastest supercomputer in the world, one of the fastest AI supercomputers in the world. It's the most energy-efficient supercomputer in the world, and it broke every single record in MLPerf, and that kind of shows you something about the scale that we work and the complexity of the work that we do. This is the future. It's for -- the future is about data centers.",546
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710487.0,Question and Answer Operator Message,Operator,,Operator,35,"We have no further questions at this time. Jensen Huang, I turn the call back over to you.",18
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710488.0,Answer,Jen-Hsun Huang,,Executives,36,"Thank you. The accelerated computing model we pioneered has clearly passed the tipping point. Adopting of NVIDIA computing is accelerating. On this foundation and leveraging one architecture, we have transformed our company in 3 dimensions. First, NVIDIA is a full stack computing platform company, offering the world's most dynamic industries, the chips systems, software and libraries like NVIDIA AI to tackle their most pressing challenges. NVIDIA -- second, NVIDIA is a data center-scale company with capabilities to architect, build and operate the most advanced data centers. The data center is the new computing unit. With this capability, we can create modern data center architectures that are computer maker partners, and then scale out to the world's industry. Third, NVIDIA is a software-defined company today, with rich software content like GeForce NOW, NVIDIA virtual workstation in the cloud, NVIDIA AI and NVIDIA Drive that will add recurring software revenue to our business model. 
In the coming years, AI will revolutionize software. Robotics will automate machines, and the virtual and physical worlds will become increasingly integrated through VR and AR. Industry advancements will accelerate, and NVIDIA accelerated computing will play an important role. 
Our next GTC will be coming on October 5, again from my kitchen. Join me. I have some exciting developments to share with you. Thanks, everyone.",217
32307.0,"NVIDIA Corporation, Q2 2021 Earnings Call, Aug 19, 2020",2020-08-19,48.0,Earnings Calls,NVIDIA Corporation,3658.0,2104104.0,82710489.0,Question and Answer Operator Message,Operator,,Operator,37,This concludes today's conference call. You may now disconnect.,10
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480822.0,Presentation Operator Message,Operator,,Operator,0,"Good afternoon. My name is Jason, and I will be your conference operator today. At this time, I would like to welcome everyone to NVIDIA's third quarter financial results conference call. [Operator Instructions] Simona Jankowski, you may begin your conference.",40
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480823.0,Presenter Speech,Simona Stefan Jankowski,,Executives,1,"Thank you. Good afternoon, everyone, and welcome to NVIDIA's conference call for the third quarter of fiscal 2021. With me on the call today from NVIDIA are Jensen Huang, President and Chief Executive Officer; and Colette Kress, Executive Vice President and Chief Financial Officer. 
I'd like to remind you that our call is being webcast live on NVIDIA's Investor Relations website. The webcast will be available for replay until the conference call to discuss our financial results for the fourth quarter of fiscal 2021. 
The content of today's call is NVIDIA's property. It can't be reproduced or transcribed without our prior written consent. 
During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties, and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today's earnings release, our most recent forms 10-K and 10-Q and the reports that we may file on Form 8-K with the Securities and Exchange Commission. 
All our statements are made as of today, November 18, 2020, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements.
During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our website.
With that, let me turn the call over to Colette.",254
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480824.0,Presenter Speech,Colette Kress,,Executives,2,"Thank you, Simona. 
Q3 was another exceptional quarter with record revenues of $4.73 billion, up 57% year-on-year, up 22% sequentially and well above our outlook. Our new NVIDIA Ampere GPU architecture is ramping with excellent demand across our major market platforms. 
Q3 was also a landmark quarter both for us and the industry as a whole as we announced plans to acquire Arm from SoftBank for $40 billion. We are incredibly excited about the combined company's opportunities, and we are working through the regulatory approval process. For today, we will focus our remarks on our quarterly performance. 
Starting with Gaming. Revenue was a record $2.27 billion, up 37% year-on-year, up 37% sequentially and ahead of our high expectations. Driving strong growth was our new NVIDIA Ampere architecture-based GeForce RTX 30 Series of gaming GPUs. The GeForce RTX 3070, 3080 and 3090 GPUs offer up to 2x the performance and 2x the power efficiency over the previous Turing-based generation. Our second-generation NVIDIA RTX combines ray tracing and AI to deliver the greatest ever generational leap in performance. 
First announced on September 1 and ranging in price from $499 to $1,499, these GPUs have generated amazing reviews and overwhelming demand. PC World called them ""staggeringly powerful"" while Newegg cited ""more traffic than Black Friday."" Many of our retail and Etail partners sold out instantly. The RTX 30 series drove our biggest ever launch. 
While we had anticipated strong demand, it exceeded even our bullish expectations. Given industry-wide capacity constraints and long cycle times, it may take a few more months for product availability to catch up with demand. 
In addition to the NVIDIA Ampere GPU architecture, we announced powerful new tools for gamers as well as for tens of millions of live streamers, broadcasters, eSports professionals, artists and creators. NVIDIA Reflex is a new technology that improves reaction time in games, reducing system latency by up to 50%. NVIDIA Reflex is being integrated into popular eSports games such as Apex Legends, Call of Duty: Warzone, Fortnite and Valorant. 
NVIDIA Broadcast is a universal plug-in for videoconferencing and live streaming applications that enhances the quality of microphones, speakers and webcams with NVIDIA AI effects such as audio noise removal, virtual background effects and webcam audio frame. With it, remote workers and live streamers can turn any room into a broadcast studio. 
Blockbuster games continue to adopt NVIDIA's RTX ray tracing and AI technology. At the games announced at Fortnite, which has more than 350 million players worldwide, it's adding NVIDIA RTX real-time ray tracing, NVIDIA DLSS AI super-resolution and NVIDIA Reflex, making the game more beautiful and even more responsive. 
Other major new titles featuring RTX this holiday season includes Watch Dogs: Legions, Call of Duty: Black Ops Cold War and much anticipated Cyberpunk 2077. 
Gaming laptop demand was also strong with double-digit year-on-year growth for the 11th quarter in a row. NVIDIA GeForce laptops support the most demanding applications for creators and designers, while doubling as a powerful gaming rig by night.
We also had record gaming console revenue on strong demand for the Nintendo Switch. And we continue to grow our cloud gaming service, GeForce NOW, which has doubled in the past 7 months to reach over 5 million registered users. GeForce NOW is unique as an open platform that connects to popular game stores including Steam, Epic Games and Ubisoft Connect, allowing gamers access to the titles they already own. 750 games are currently available on GFN, the most of any cloud gaming platforms, including 75 free-to-play games, with more games added every Thursday. GFN supports many popular clients including PCs, Macs and Chromebooks. Stay tuned for more devices to come in the near future. 
In addition, GFN's reach continues to expand through our telco partners in a growing list of countries including Japan, Korea, Taiwan, Russia and Saudi Arabia. We are also providing technology that enables the cloud gaming services to an expanding number of partners. Following our earlier announcement with Tencent, Amazon and Facebook are beginning to offer cloud gaming services powered by NVIDIA. 
Moving to Pro Vis. Q3 revenue was $236 million, down 27% year-on-year and up 16% sequentially, ahead of our expectations. Sequential growth was driven by strength in notebooks, which posted record revenue, boosted by work-from-home initiatives and the shift to thin and light mobile workstations. This was particularly offset by a decline in desktop workstations, which continued to be impacted by the pandemic and drove the year-on-year decline. 
From an industry demand perspective, stronger verticals including health care, public sector, higher education and research and financial services, we continue to win new business in a number of areas. In health care, we added Medtronic for visual surgical applications and Philips for medical imaging. In technology and media and entertainment, we gained wins for design, rendering and broadcast applications. During the quarter, we announced that Omniverse, the world's first 3D collaboration and simulation platform, has entered open beta. Omniverse enables the tens of millions of designers, architects and creators to collaborate real-time on-premises or remotely. Fusing the virtual and physical world, Omniverse brings together NVIDIA breakthroughs in graphics, simulation and AI. It will help enterprises address evolving requirements as workforces become increasingly distributed. 
Initial market response from this transformative platform has been phenomenal. Over 400 individual creators and developers in diverse industries have been evaluating Omniverse and early adopters including Ericsson, BMW, Foster + Partners and Lucasfilm.
The pandemic is accelerating development of AR, VR and mixed reality technologies, which will have a profound impact on how we work and play. For example, our work with NASCAR to enable a variety of AR and VR services at the edge is revolutionizing the racing experience for millions of fans across the globe. With our industry-leading real-time ray tracing graphics, AI and simulation hardware and software stacks, NVIDIA is in a unique position to enable the future of blending the physical and virtual worlds. 
Moving to Automotive. Q3 revenue was $125 million, down 23% year-on-year and up 13% sequentially. Sequential growth was driven by a recovery in global automotive production volumes as well as continued growth in AI cockpit revenue. The year-on-year decline was due to the expected ramp down of legacy infotainment revenue. 
In September, Mercedes-Benz debuted its redesign of S-Class sedan featuring an all-new NVIDIA-powered MBUX AI cockpit system with an augmented reality heads-up display, AI voice assistant and rich interactive graphics to enable every passenger in the vehicle to enjoy personalized intelligent features. Also in September, Li Auto, a leading electric car brand in China, announced that it will develop its next generation of vehicles using the software-defined NVIDIA Drive AGX Orin platform. Orin delivers nearly 7x the performance and 3x the energy efficiency of our previous generation SSC, making it uniquely capable to power next-generation autonomous electric vehicles. We have excellent traction with EV start-ups. 
Finally, last week, NVIDIA and Hyundai Motor Group announced that the automaker's entire lineup of Hyundai, Kia and Genesis models will come standard with NVIDIA DRIVE in-vehicle infotainment systems starting in 2022. This feature-rich software-defined computing platform will allow vehicles to be perpetually upgraded with the latest AI cockpit features. 
Now moving to Data Center. Revenue was a record $1.9 billion, up 162% year-over-year and up 8% sequentially. Driving growth was the strong ramp of our A100-based platforms, continued growth with Mellanox and record T4 shipments for inference. Let me give you a little bit of color on each. 
Our new NVIDIA Ampere architecture gained further adoption by cloud and hyperscale customers and started ramping into vertical industries. Over the past weeks, Amazon Web Services, Oracle Cloud Infrastructure and Alibaba Cloud announced general availability of the A100 following Google Cloud Platform and Microsoft Azure. A100 adoption by vertical industries drove strong growth as we began shipments to server OEM partners, whose broad enterprise channels reach a large number of end customers. 
We also ramped the DGX A100 server and began shipping NVIDIA DGX SuperPOD, the first turnkey AI infrastructure. These range from 20 to 140 DGX A100 systems interconnected with Mellanox's HDR InfiniBand networking and enable customers to install incredibly powerful AI supercomputers in just a few weeks' time. In fact, we have announced plans to build an 80-node DGX SuperPOD with 400 petaflops of AI performance called Cambridge-1, which will be in the U.K.'s fastest AI supercomputer that will be used by NVIDIA researchers for collaborative research within the U.K.'s AI and health care community across academia, industries and start-ups. It joins other systems in NVIDIA's complex of AI supercomputers powered by our R&D and autonomous vehicles, conversational AI, robotics, graphics, HPC and other domains. This includes Selene, now the world's fifth fastest supercomputer and fastest commercial supercomputer, and the new NVIDIA DGX SuperPOD, which ranks first on the Green500 list of the world's most energy-efficient supercomputers. 
A great example of the tremendous opportunities for AI and health care is our new partnership with GSK for applying computational to the drug and vaccine discovery process. GSK's London-based AI hub will utilize biomedical data, AI methods and advanced computing platforms to unlock genetic and clinical data with increased precision and scale. 
In addition to this investment in NVIDIA's DGX A100 system, GSK will have access to NVIDIA's Cambridge-1, the NVIDIA Clara Discovery software and NVIDIA scientists. 
In Q3, the A100 swept the industry standard MLPerf benchmark for AI inference performance following our sweep in the prior quarter's MLPerf benchmark for AI training. Notably, our performance lead in AI inference actually extended compared with last year's benchmark. For example, in the ResNet-50 test for image recognition, our A100 GPU beat CPU-only system by 30x this year versus 6x last year. Additionally, A100 outperformed CPUs by up to 237x in the newly added recommender test, which represents some of the most complex and widely used AI models on the Internet. 
Our winning performance in AI inference is translating to continued strong revenue growth. Alongside the continued ramp of the A100, T4 sales set a record as the NVIDIA AI inference adoption is in full throttle. We estimate that NVIDIA's installed GPU capacity for inference across the 7 largest public clouds now exceeds that of the aggregate CPU capacity in the cloud, a testament to the tremendous performance and TCO advantage of our GPUs. Hundreds of companies now operate AI-enabled services on NVIDIA's inference platform, including the A100 or T4 GPU and our Triton Inference serving software. For example, Tencent uses NVIDIA AI inference to recommend videos, music, news and apps, supporting billions of queries per day. Microsoft uses NVIDIA AI inference for grammar correction in Microsoft Office, supporting 0.5 trillion queries a year. And American Express uses it for real-time fraud detection. 
We also gave tremendous traction in supercomputing. We announced that NVIDIA technology, including Ampere architecture GPUs and HDR InfiniBand networking, will power 5 systems awarded by Euro HPC, a European initiative to build exascale supercomputing. This includes Cineca, a university consortium in Italy and one of the world's most important supercomputing centers, which will use NVIDIA's accelerated computing platform to build the world's fastest AI supercomputer. Cineca's supercomputer named Leonardo advances the age of exascale AI, delivering 10 exaflops of AI performance to enable AI and high-performance computing converge application use cases. It is built with nearly 14,000 NVIDIA Ampere architecture-based GPUs and Mellanox HDR 200-gigabit per second InfiniBand networking. And just released top 500 list of supercomputers show that NVIDIA GPUs or networking powered nearly 70% and 8 of the 10 top supercomputers on the list. 
Mellanox had another record quarter with double-digit sequential growth well ahead of our expectations, contributing 13% of overall company revenue. The upside reflected sales to a China OEM that will not recur in Q4. As a result, we expect a meaningful sequential revenue decline for Mellanox in Q4, though still growing 30% from last year. Mellanox reached record revenue in both InfiniBand and Ethernet driven by cloud, enterprise and supercomputing customers. Strong demand for high-performance interconnects where Mellanox is a leader is being fueled by AI and increasingly complex applications which demand faster, smarter, lower scalable networks. As the data center becomes the new unit of computing in the age of AI, Mellanox networking is foundational to modern scale-out architectures.
At GTC in October, we unveiled the BlueField-2 DPU, or data processing unit, a new kind of processor which offloads critical networking, storage and security task from the CPU. A single BlueField 2 DPU can deliver the same data center services that consume up to 125 CPU cores. This frees up valuable CPU cores to run a wide range of other enterprise applications. In addition, it enables zero trust security features to prevent data breaches and cyberattacks and accelerates overall performance. VMware announced that it will offload, accelerate and isolate its industry leading ESXi Hypervisor with NVIDIA's BlueField-2 DPU, boosting vSphere and data center performance and efficiency. 
We also unveiled our 3-year DPU road map, unifying Mellanox's leading network capabilities with NVIDIA's GPU and the new NVIDIA DOCA, or data center on a chip, architecture, software development kit for building DPU-accelerated applications. We believe that over time, DPUs will ship on millions of servers, unlocking a $10 billion total addressable market. BlueField-2 is sampling now with major hyperscale customers and will be integrated into the enterprise server offerings of major OEMs. 
This was our busy period for product launches. Earlier this week at Supercomputing '20, we announced the new double-capacity A100 80-gigabyte GPUs and DGX systems for organizations to build, train and deploy massive AI models. We also announced the new DGX Station A100, a powerful workgroup server with 4 A100 GPUs and a massive 320-gigabyte GPU memory for data scientists and AI researchers working in offices, research facilities, labs or at home. All these additions to the NVIDIA Ampere architecture family of products will be available early next year. 
At SC20, we also announced the next-generation NVIDIA Mellanox 400-gigabit per second InfiniBand architecture, getting AI developers and scientific researchers the fastest available networking performance. This doubles data throughput and adds new in-network computing engines to provide additional acceleration. Solutions based on this new architecture are expected to sample in the second quarter of calendar 2021.
Moving to the rest of the P&L. Q3 GAAP gross margins was 62.6%, and non-GAAP gross margin was 65.5%. GAAP gross margin declined year-on-year, primarily due to charges related to the Mellanox acquisition partially offset by product mix. This sequential increase was driven by the absence of nonrecurring inventory step-up expense related to the Mellanox acquisition. 
Non-GAAP gross margins increased by 140 basis points year-on-year, reflecting a shift in product mix with higher Data Center sales, including the contribution from Mellanox. Non-GAAP gross margin was down 50 basis points sequentially, in line with our expectations, driven by product mix. 
Q3 GAAP operating expenses were $1.56 billion, and non-GAAP operating expenses were $1.1 billion, up 6% and 42% from a year ago, respectively. 
Q3 GAAP EPS was $2.12, up 46% from a year earlier. And non-GAAP EPS was $2.91, up 63% from a year ago. Q3 cash flow from operations was $1.28 billion. 
With that, let me turn to the outlook for the fourth quarter of fiscal 2021. As a reminder, Q4 includes a 14th week, which we expect to be incrementally an addition to revenue and operating expenses. 
We expect Gaming to be up sequentially in what is typically a seasonally down quarter as we continue to ramp up our new RTX 30 Series products. We expect Data Center to be down slightly versus Q3. 
With that, we expect computing products to grow in the mid-single digits sequentially, more than offset by a sequential decline in Mellanox. We expect continued sequential growth in Auto and Pro Vis though not yet returning to year-on-year growth. And we expect a seasonal decline in OEM. 
Revenue is expected to be $4.8 billion, plus or minus 2%. GAAP and non-GAAP gross margins are expected to be 62.8% and 65.5%, respectively, plus or minus 50 basis points. 
GAAP and non-GAAP operating expenses are expected to be approximately $1.64 billion and $1.18 billion, respectively. GAAP and non-GAAP other income and expenses are both expected to be an expense of approximately $55 million. 
GAAP and non-GAAP tax rates are both expected to be 8%, plus or minus 1%, excluding discrete items. Capital expenditures are expected to be approximately $300 million to $325 million. Further financial details are included in the CFO commentary and other information available on our IR website.
In closing, let me highlight upcoming events for the financial community. We'll be virtually attending the Crdit Suisse Technology Conference on November 30; Wells Fargo TMT Summit, December 1; and the UBS TMT Conference on December 7. Our earnings call to discuss the fourth quarter and full year results is scheduled for Wednesday, February 24. 
We will now open the call for questions. Operator, would you please poll for questions?",2818
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480825.0,Question and Answer Operator Message,Operator,,Operator,3,[Operator Instructions] Your first question comes from the line of John Pitzer from Crdit Suisse.,15
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480826.0,Question,John Pitzer,,Analysts,4,"Sorry, can you hear me?",5
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480827.0,Answer,Jen-Hsun Huang,,Executives,5,Yes.,1
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480828.0,Question,John Pitzer,,Analysts,6,"Congratulations on the solid results. Just Colette, going back to your commentary around Mellanox, it seems like you're guiding the January quarter to about 500 million, which means the core data center business is still growing nicely, call it, 6%, 7% sequentially. I'm just kind of curious when you look at the core data center business, I know there's not a direct correlation to server business, but we're clearly going through a cloud digestion in server and core vertical markets enterprise for servers are weak. 
When you look at your core data center business, do you feel as though that's having an impact and this is sort of the digestion that you saw kind of in late fiscal '20 into -- sorry, fiscal '19 into '20, but you're doing it still growing significantly year-over-year? Or how would you characterize the macro backdrop?",142
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480829.0,Answer,Colette Kress,,Executives,7,"Sure. Let me make sure we clarify for those also on the call. Yes, we expect our Data Center revenue in total to be down slightly quarter-over-quarter. The computing products, NVIDIA computing products, is expected to grow in the mid-single digits quarter-over-quarter as we continue the NVIDIA AI adoption and particularly as A100 continues to ramp. 
Our networking, our Mellanox networking, is expected to decline meaningful quarter-over-quarter as sales to that China OEM will not recur in Q4, though we still expect the results to be growth of 30% or more year-over-year. The timing of some of this business therefore shifted from Q4 to Q3. But overall, H2 is quite strong. 
So in referring to overall digestion, the hyperscale business remains extremely strong. We expect hyperscales to grow quarter-over-quarter in computing products as A100 continues to ramp. The A100 continues to gain adoption not only across those hyperscale customers, but again we're also receiving great momentum in inferencing with the A100 and the T4. 
I'll turn it over here to Jensen to see if he has more that he would like to add.",183
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480830.0,Answer,Jen-Hsun Huang,,Executives,8,"Yes. Colette captured it very well. The only thing I would add is our inference initiative is really gaining great momentum. Inference is one of the hardest computer science problems. Compiling these gigantic neural network computational graphs into a target device is really, really -- has proven to be really, really hard. The models are diverse, ranging from vision to language to speech. And there are so many different types of models being created. The model sizes are doubling every couple of months. The latency expectations are increasing all the time -- or latency is decreasing all the time. 
And so the pressure on inference is really great. The technology pressure is really great. And our leadership there is really pulling ahead. We're in our seventh generation TensorRT. 
We, over the course of the last couple of years, developed an inference server. It's called Triton, has been adopted all over the place. We have several hundred customers now using NVIDIA AI to deploy their AI services. 
This is the early innings, and I think this is going to be our largest near-term growth opportunity. So we're really firing on all cylinders there, between the A100s ramping in the cloud, A100s beginning to ramp in enterprise, and all of our inference initiatives are really doing great.",215
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480831.0,Question,John Pitzer,,Analysts,9,"Jensen, maybe to follow on there, just on the vertical markets, clearly work from home and COVID this year kind of presented a headwind to new technology deployments on-prem. I'm kind of curious, if we expect sort of an enterprise recovery in general next year, how do you think that will translate into your vertical market strategy? And is there anything else above and beyond that you can do to help accelerate penetration of AI into that end market?",79
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480832.0,Answer,Jen-Hsun Huang,,Executives,10,"Yes. John, that's a good point. I mean the -- it's very clear that the inability to go to work is slowing down the adoption of new technology in some of the verticals. Of course, we're seeing rapid adoption in certain verticals, like for example using AI in health care to rapidly discover new vaccines and early detection of outbreaks and robotic applications. So warehouses, digital retail, last mile delivery, we're just seeing just really, really great enthusiasm around adopting new AI, robotics technology. But in some of the old -- some of the more traditional industries, new capabilities and new technologies are slower to deploy. 
One of the areas that I'm really super excited about is the work that we're doing in the remote work and making it possible for people to collaborate remotely. We have a platform called Omniverse. It's in early beta. The feedback from the marketplace has been really great. And so I've got a lot more to report to you guys in the upcoming months around Omniverse. 
And so -- but anyways, I think when the industry recover, we serve -- our fundamental purpose as a company is to solve the greatest challenges that impact the industry where ordinary computers can't. And these challenges are -- serve some of the most important applications in the verticals that we address. And they're not commodity applications. They're really impactful, needle-moving applications. So I have every confidence that when the industries recover, things will get designed. Cars will be designed, and planes will be designed, and ships will be designed, and buildings will be designed. And we're going to see a lot of design, and we're going to see a lot of simulation. We're going to see a lot of robotics applications.",294
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480833.0,Question and Answer Operator Message,Operator,,Operator,11,[Operator Instructions] Your next question comes from the line of C.J. Muse from Evercore.,14
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480834.0,Question,Christopher Muse,,Analysts,12,You talked about in your prepared remarks limited availability of capacity components. You suggested perhaps a few months to catch up. Curious if you can speak to the visibility that you have for both Gaming and Data Center into your April quarter.,42
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480835.0,Answer,Jen-Hsun Huang,,Executives,13,"Yes. Colette, do you want me to take that real quick and maybe you can help me out?",18
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480836.0,Answer,Colette Kress,,Executives,14,"Yes. Yes, absolutely.",3
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480837.0,Answer,Jen-Hsun Huang,,Executives,15,"So C.J., first off, we have a lot of visibility into the channel, as you know, especially for Gaming. And we know how many weeks of inventory is in what parts of the channel. 
We've been draining down the channel inventory for Turing for some time. And meanwhile, we've also expected a very, very successful launch with Ampere. And even with our bullish demand expectation and all of the Amperes that we built, which is one of the fastest ramps ever, the demand is still overwhelming. 
And this, I guess in a lot of ways, is kind of expected. The circumstances are -- it's been a decade since we've invented a new type of computer graphics. 10 years ago, we invented a programmable shader, and it set the industry on a course to create the type of images that we see today. 
But it's very clear that the future is going to look something much, much more beautiful, and we invented NVIDIA RTX to do that. And it has 2 capabilities, one based on ray tracing, and the other one's based on artificial intelligence image generation. The combination of those 2 capabilities is creating images that people are pretty ecstatic about. And at this point, it's defined the next-generation content. 
And so when we -- it took us 10 years to invent it. We launched it 2 years ago and took our second generation to really achieve the level of quality and performance that the industry really, really expect. And now the demand is just overwhelming. And so we're going to continue to ramp fast, and this is going to be one of our most successful ramps ever. And it gives our installed base of some 200 million-plus GeForce gamers the best reason to upgrade in over a decade. And so this is going to be a very large generation for us is my guess. 
And then with respect to Data Center, we're ramping into A100. A100 is our first generation of GPUs that does several things at the same time. It's universal. We position it as a universal because it's able to do all of the applications that we in the past had to have multiple GPUs to do. It does training well. It does inference incredibly well. It does high-performance computing. It does data analytics. And so it's able -- the Ampere architecture is able to do all of this at the same time. And so the utilization for data centers is -- and the utility is really, really fantastic. And the reception has been great. 
And so we're going to ramp into all of the world's clouds. I think starting this quarter, we're now in every major cloud provider in the world, including Alibaba, Oracle, and of course the giants, the Amazons, the Azure and the Google Clouds. And we're going to continue to ramp into that. 
And then of course we're starting to ramp into enterprise, which in my estimation long term will still be the largest growth opportunity for us, turning every industry into an AI, turning every company into AIs and augment it with Al and bringing the iPhone moment to all of the world's largest industries. And so we're ramping into that, and we're seeing a great deal of enthusiasm.",548
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480838.0,Question and Answer Operator Message,Operator,,Operator,16,Your next question comes from the line of Stacy Rasgon from Bernstein Research.,13
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480839.0,Question,Stacy Rasgon,,Analysts,17,"You said that the extra week was contributing incrementally to revenue and OpEx. Can you give us some feeling for how much is contributing to revenue and OpEx in Q4? And does that impact, at least on the revenue side, differ, say, between like Gaming and Data Center? And then how should we think about it impacting seasonality into Q1 as that extra week rolls off?",66
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480840.0,Answer,Colette Kress,,Executives,18,"Sure. Let me try this one, Jensen.
Yes, we've incorporated that 14th week into our guidance for both revenue and OpEx. We will likely have incrementally positive impact on revenue, although it is tough to quantify, okay? 
Our outlook also reflects incremental OpEx for Q4 in primarily 2 different areas in terms of compensation and depreciation. And given that our employees are such a material part of our OpEx, it will -- it can be close to 1/14 of the quarter. 
Now when we look a little bit further, we should think about the incremental positive in both Gaming and Data Center from that extra week as there hopefully will be extra supply, but not likely as much as 1/14 of the quarter of revenue as enterprise demand is essentially project-based and gaming demand though is tied to the number of gamings that -- gamers that might be shopping for the overall holiday. So again, still very hard for us to determine at this time. 
Normally, between Q4 and Q1, there is seasonality in Gaming, seasonality downward. But we'll just have to see as we are still supply-constrained within this Q4 to see what that looks like. 
From an OpEx standpoint, we'll probably expect our OpEx to be relatively flattish as we move from Q4 to Q1.",217
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480841.0,Question and Answer Operator Message,Operator,,Operator,19,Your next question comes from the line of Vivek Arya from Bank of America.,14
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480842.0,Question,Vivek Arya,,Analysts,20,"Congratulations on the strong growth. Jensen, my question is on competition from internally designed products by some of your larger cloud customers, Amazon and Google and others. We hear about competition from time to time, and I wanted to get your perspective. Is this a manageable risk? Is the right way to think that they are perhaps using more of your product in their public cloud, but they are moving to internal products for internal workloads? Just how should we think about this risk going forward?",86
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480843.0,Answer,Jen-Hsun Huang,,Executives,21,"Thanks, Vivek. Most of the cloud vendors, in fact I believe all of the cloud vendors, use the same infrastructures largely for their internal cloud and external cloud, or have the ability to or largely do. And there's -- the competition, we find to be really good. 
And the reason for that is this. It just suggests that acceleration -- makes it very clear that acceleration is the right path forward for training and inference. The vast majority of the world's training models are doubling in size every couple of months, and it's one of the reasons where our demand is so great. 
The second is inference. The vast majority of the world's inference is done on CPUs. And nothing is better than the whole world recognizing that the best way forward is to do inference on accelerators. And when that happens, our accelerator is the most versatile. It's the highest performance. We move the fastest. Our rate of innovation is the fastest because we're also the most dedicated to it. We're the most committed to it, and we have the largest team in the world to it. Our stack is the most advanced, giving us the greatest versatility and performance. 
And so we see spots of announcement here and there, but they're also our largest customers. And as you know that we're ramping quite nicely at Google, we're ramping quite nicely at Amazon and Microsoft and Alibaba and Oracle and others. 
And so I think the big takeaway is that -- and the great opportunity for us if you look at the vast amount of workload, AI workload in the world, the vast majority of it today is still on CPUs. And it's very clear now this is going to be an accelerated workload, and we're the best accelerator in the world. And this is going to be a really big growth opportunity for us in the near term. In fact, we believe it's our largest growth opportunity in the near term, and we're in the early innings of it.",341
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480844.0,Question and Answer Operator Message,Operator,,Operator,22,Your next question comes from the line of Harlan Sur from JPMorgan.,12
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480845.0,Question,Harlan Sur,,Analysts,23,"Great job on the quarterly execution. The Mellanox networking connectivity business was up 80% year-over-year. I think it was up about 13%, 14% sequentially. And I know there was upside in October from one China customer. But it did grow 70% year-over-year last quarter, and you're still expecting 30% year-over-year growth next quarter. If I remember correctly, I think InfiniBand is about 40% of that business; ethernet cloud is about 60%. 
Jensen, what are the big drivers, especially since we're in the midst of a cloud spending digestion cycle? And I just saw that the team announced their next-gen 400-gig InfiniBand solution, which should drive another strong adoption cycle with your supercomputer customers. When does this upgrade cycle start to fire?",121
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480846.0,Answer,Jen-Hsun Huang,,Executives,24,"Yes. Let's see. Our Data Center business consists of supercomputing centers, which is small, High-performance computing was a much larger part of supercomputing, much larger than supercomputing. And then hyperscale and enterprise, which -- about 50-50. 
The -- of the Data Center business, the accelerated computing part is not very much associated with digestion and others. It's much more associated with workloads and our new product cycles, the TCO that we bring and AI inference, the type of models that the cloud service providers are deploying, whether they're deploying new AI models based on deep learning, and how much of it that we -- how much of those workloads that we've completed the porting to our accelerators and readying it for deployment. 
And so those are the factors associated with accelerated computing. It's really about the apps. It's really about the workloads and really driven by AI. 
On the other hand, the networking part of our business is more connected to CPU business because they're much more broad-based. The networking part of our business is driven by this idea of new hyperscale data center architecture called disaggregation. It's software disaggregation, not necessarily hardware disaggregation. Software disaggregation, where this type of software called Kubernetes orchestrate micro services that are deployed across the data center. So one service, one application, isn't monolithic running on one computer anymore. It's distributed across multiple computers and multiple nodes, so that the hyperscale data centers can more easily scale up and scale out according to the workloads and according to the demand on the data center. 
And so this disaggregation has caused the networking between the compute nodes to be of all vital importance. And because Mellanox is the lowest-latency, highest-performance, highest-bandwidth network that you can get, that the TCO benefit at the data center scale is really fantastic. And so when they're building out data centers, Mellanox is going to be much more connected to that. 
In the enterprise side of it, depending on new CPU cycles, it could affect them. If a CPU cycle were to delay a little bit, it would affect them by a quarter. But if it was a pull-in by a quarter, it would affect them by a pull-in of a quarter. 
And so those are kind of the dynamics of it. I think that the net-net of it is that it's a foregone conclusion at this point, that AI is going to be the future of the way software is written. AI is the most powerful technology force of our time, and acceleration is the best path forward. And so that's what drives our computing business. And the networking business has everything to do with the way -- architecture of data centers, cloud data centers, which is architected with micro services now. And that's what foundationally drives their -- our networking business demand. And so we're really well positioned in these 2 fundamental dynamics because, as we know, AI is the future and cloud computing is the future. Both of those dynamics are very favorable to us.",508
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480847.0,Question and Answer Operator Message,Operator,,Operator,25,Your next question comes from the line of Timothy Arcuri from UBS.,12
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480848.0,Question,Timothy Arcuri,,Analysts,26,"I wanted to ask a question that was asked before but in a different way. If I look at the core business excluding Mellanox, the core data center business, it was up about 6% sequentially the past 2 quarters, and your guidance sort of implies up about that much again in January, which is certainly good under some cloud digestion, but of course you have Ampere still ramping as well, which should be a pretty good tailwind. So there seems to be some offsetting factors. 
So I guess I wonder if you feel like your core data center revenue is still being constrained right now by some market digestion and kind of how you sort of balance or handicap these 2 factors.",122
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480849.0,Answer,Jen-Hsun Huang,,Executives,27,"Our growth is -- in the near term is more affected by the cycle time of manufacturing and flexibility of supply. We are in a good shape to -- and all of our supply is -- informs our guidance. But we would appreciate shorter cycle times. We would appreciate more agile supply chains. But the world is constrained at the moment. And so we just have to make the best of it. But even in that condition, we've -- all of that is in our guidance, and we expect to grow.",91
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480850.0,Question and Answer Operator Message,Operator,,Operator,28,Your next question comes from the line of Aaron Rakers from Wells Fargo.,13
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480851.0,Question,Aaron Rakers,,Analysts,29,"Congratulations on the quarter. I wanted to go back to kind of the Mellanox question. I know prior to the acquisition, Mellanox was growing maybe in the mid- to high 20% range. These last 2 quarters, it's grown over 75%. 
I guess the simple question is how do you think about the growth rate for Mellanox going forward? And on that topic, we've started to hear you talk more about BlueField and data processing units. I think in your commentary, you alluded to server OEM design wins incorporating these DPUs. 
What are you looking at? Or when should we think about the DPU business really starting to inflect and become a material driver for the business?",116
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480852.0,Answer,Jen-Hsun Huang,,Executives,30,"Long term, every computer in the world will be built like a data center, and every node of a data center is going to be a data center in itself. And the reason for that is because we want the attack surface to be basically 0. And today, most of the data centers are only protected as a periphery. But in the future, if you would like cloud computing to be the architecture for everything and every data center is multi-tenant, every data center is secure, then you're going to have to secure every single node. And each one of those nodes are going to be a software-defined networking, software-defined storage, and it's going to have per application security. 
And so the processing that is -- that it will need to offload the CPU is really quite significant. In fact, we believe that somewhere between 20% to 40% of today's data centers, cloud data centers is the capacity, the throughput, the computational load is consumed running basically the infrastructure overhead. 
And that's what the DPU is intended -- was designed to do. We're going to offload that, number one. And number two, we're going to make every single application secure. And confidential competing, zero trust computing, that will become a reality. 
And so the importance is really quite tremendous. And I believe therefore that every single server in the world will have a DPU inside someday just because we care so much about security and just because we care so much about throughput and TCO. And it's really the most cost-effective way of building a data center. And so I expect our DPU business to be quite large. 
And so that's the reason why we're putting so much energy into it. It's a programmable data center on a chip, think of it that way, a data center infrastructure on a chip. It is the reason why we're working with VMware on taking the operating system in the data center, the software-defined operating system in the data center, putting it on the BlueField. And so this is a very important initiative for us. I'm very excited about it, as you can imagine.",361
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480853.0,Question and Answer Operator Message,Operator,,Operator,31,Your next question comes from the line of Ambrish Srivastava from BMO Capital Markets.,14
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480854.0,Question,Ambrish Srivastava,,Analysts,32,"Colette, and I apologize if I missed it, but for Mellanox, do you expect it to get back to the growth trajectory on a sequential basis in the April quarter? And I'm assuming that the shortfall in the current quarter is from a pull-in from Huawei.",46
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480855.0,Answer,Colette Kress,,Executives,33,"So our impact to our Q4 guidance for Mellanox, yes, is impacted by a sale to a China OEM for Mellanox that will not recur in Q4. And as we look forward into Q1 of April, we're going to take this a quarter at a time and provide thoughts and guidance for that once we turn the corner to the new fiscal year.",63
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480856.0,Answer,Jen-Hsun Huang,,Executives,34,"At the highest level, Colette, I think the -- it's safe to say that high-speed networking is going to be one of the most important things in cloud data centers as we go forward. And the vast majority of the world's data center is still built for the traditional hyper-converged architecture, which is all moving over to micro services-based disaggregate -- software-defined disaggregated architectures. And that journey is still in its early days. 
And so I fully expect future cloud data centers, all future data centers are going to be connected with high-speed networking inside. They call it east-west traffic. And all of the traffic will be secured. And so imagine building firewalls into every single server. And imagine every single transaction, every single transmission inside the data center to be high speed and fully encrypted. 
And so pretty amazing amount of computation is going to have to be installed into future data centers. But that's an accepted requirement now. And I think our networking business, Mellanox, is in the early innings of growth.",174
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480857.0,Question and Answer Operator Message,Operator,,Operator,35,Your final question today comes from the line of William Stein from Truist Securities.,14
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480858.0,Question,William Stein,,Analysts,36,"You've given us some pieces of this puzzle, but I'm hoping maybe you can address directly the sort of SKU-by-SKU rollout of Ampere. We know that we didn't have a ton of SKUs last quarter. There were more in this quarter that you just announced. Now you're doing sort of this refresh, it sounds like, with double the memory on the A100. 
Is the T4 going to be refreshed? And if so, when does that happen? And are there other either systems or chips that are still waiting for the Ampere refresh that could potentially contribute to an extended cycle as we look at the next year?",108
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480859.0,Answer,Jen-Hsun Huang,,Executives,37,"Yes. In terms of the total number of SKUs that we've ramped of Ampere, we're probably somewhere along 1/3 to 1/2 of the SKUs at this point, maybe a little bit less. Yes, it's less. 
The way that you could think through it, you could reverse engineer it is like this. You know what our Gaming lineup looks like for desktops. And so traditionally we try to have a new architecture in every single segment. And we've not gone below 499 yet. And so there's a very big part of the marketplace that we're still in the process of addressing. 
And then the second thing is laptops. None of those -- none of the Ampere architecture has launched for laptops. 
And then there's workstations. And you do the same thing with desktops workstations and laptops workstations. And none of them -- none of those have gone out yet. 
And then there's data center. In our data center business for cloud, you've seen some of the early versions of it, A100. But then there's cloud computing for graphics. There's cloud gaming. There's enterprise -- edge enterprise applications, enterprise data analytics applications. And so there's a fair number of exciting new products we still have in front of us.",207
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480860.0,Question and Answer Operator Message,Operator,,Operator,38,That concludes our Q&A for today. I now turn the call back to Ms. Jankowski for closing remarks.,19
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480861.0,Answer,Simona Stefan Jankowski,,Executives,39,"Actually, that will be for Jensen.",6
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480862.0,Question and Answer Operator Message,Operator,,Operator,40,My apologies.,2
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480863.0,Answer,Jen-Hsun Huang,,Executives,41,"Okay. Thank you. Thank you, Simona.
This was a terrific quarter. NVIDIA is firing on all cylinders. And the RTX has reinvented graphics and has made real-time ray tracing the standard of next-generation content, creating the best ever reason to upgrade for hundreds of millions of NVIDIA gamers. 
AI, where software writes software no humans can, is the most powerful technology force of our time and is impacting every industry. NVIDIA AI again swept MLPerf training and now inference as well, extending our leadership in this important new way of doing computing. 
NVIDIA AI's new Triton inference server, a platform that I will speak a lot more about in the future and a lot more frequently because it's important -- and our full stack optimized platform are gaining rapid adoption to operate many of the world's most popular AI-enhanced services, opening a major growth opportunity. 
Data centers are the new unit of computing. Someday, we believe there will be millions of autonomous data centers distributed all over the globe. 
NVIDIA's BlueField DPU programmable data center on a chip and our rich software stack will help place AI data centers in factories, warehouses, 5G base stations and even on wheels. 
And with our pending acquisition of ARM, the company that builds the most -- the world's most popular CPU, we will create the computing company for the age of AI, with computing extending from the cloud to trillions of devices. 
Thank you for joining us today. I wish all of you a happy holidays. And please do stay safe, and I look forward to seeing you guys next time.",268
32307.0,"NVIDIA Corporation, Q3 2021 Earnings Call, Nov 18, 2020",2020-11-18,48.0,Earnings Calls,NVIDIA Corporation,3720.0,2146683.0,84480864.0,Question and Answer Operator Message,Operator,,Operator,42,That concludes today's conference call. You may now disconnect.,10
